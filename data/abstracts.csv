authors,year,name,cites,content
"S Zaman, B Adams, AE Hassan",2011,Security versus performance bugs: a case study on firefox,138,"A good understanding of the impact of different types of bugs on various project aspects is essential to improve software quality research and practice. For instance, we would expect that security bugs are fixed faster than other types of bugs due to their critical nature. However, prior research has often treated all bugs as similar when studying various aspects of software quality  e.g., predicting the time to fix a bug , or has focused on one particular type of bug  e.g., security bugs  with little comparison to other types. In this paper, we study how different types of bugs  performance and security bugs  differ from each other and from the rest of the bugs in a software project. Through a case study on the Firefox project, we find that security bugs are fixed and triaged much faster, but are reopened and tossed more frequently. Furthermore, we also find that security bugs involve more developers and impact more files in a project. Our work is the first work to ever empirically study performance bugs and compare it to frequently studied security bugs. Our findings highlight the importance of considering the different types of bugs in software quality research and practice."
"J Xuan, H Jiang, Z Ren, W Zou",2012,Developer prioritization in bug repositories,147,"Developers build all the software artifacts in development. Existing work has studied the social behavior in software repositories. In one of the most important software repositories, a bug repository, developers create and update bug reports to support software development and maintenance. However, no prior work has considered the priorities of developers in bug repositories. In this paper, we address the problem of the developer prioritization, which aims to rank the contributions of developers. We mainly explore two aspects, namely modeling the developer prioritization in a bug repository and assisting predictive tasks with our model. First, we model how to assign the priorities of developers based on a social network technique. Three problems are investigated, including the developer rankings in products, the evolution over time, and the tolerance of noisy comments. Second, we consider leveraging the developer prioritization to improve three predicted tasks in bug repositories, i.e., bug triage, severity identification, and reopened bug prediction. We empirically investigate the performance of our model and its applications in bug repositories of Eclipse and Mozilla. The results indicate that the developer prioritization can provide the knowledge of developer priorities to assist software tasks, especially the task of bug triage."
"M Gegick, P Rotella, T Xie",2010,Identifying security bug reports via text mining: An industrial case study,142,"A bug tracking system such as Bugzilla contains bug reports  BRs  collected from various sources such as development teams, testing teams, and end users. When bug reporters submit bug reports to a bug tracking system, the bug reporters need to label the bug reports as security bug reports  SBRs  or not, to indicate whether the involved bugs are security problems. These SBRs generally deserve higher priority in bug fixing than not security bug reports  NSBRs . However, in the bug reporting process, bug reporters often mislabel SBRs as NSBRs partly due to lack of security domain knowledge. This mislabeling could cause serious damage to software system stakeholders due to the induced delay of identifying and fixing the involved security bugs. To address this important issue, we developed a new approach that applies text mining on natural language descriptions of BRs to train a statistical model on already manually labeled BRs to identify SBRs that are manually mislabeled as NSBRs. Security engineers can use the model to automate the classification of BRs from large bug databases to reduce the time that they spend on searching for SBRs. We evaluated the model s predictions on a large Cisco software system with over ten million source lines of code. Among a sample of BRs that Cisco bug reporters manually labeled as NSBRs in bug reporting, our model successfully classified a high percentage  78  of the SBRs as verified by Cisco security engineers, and predicted their classification as SBRs with a probability of at least 0.98."
"H Hu, H Zhang, J Xuan, W Sun",2014,Effective bug triage based on historical bug fix information,45,"For complex and popular software, project teams could receive a large number of bug reports. It is often tedious and costly to manually assign these bug reports to developers who have the expertise to fix the bugs. Many bug triage techniques have been proposed to automate this process. In this paper, we describe our study on applying conventional bug triage techniques to projects of different sizes. We find that the effectiveness of a bug triage technique largely depends on the size of a project team  measured in terms of the number of developers . The conventional bug triage methods become less effective when the number of developers increases. To further improve the effectiveness of bug triage for large projects, we propose a novel recommendation method called Bug Fixer, which recommends developers for a new bug report based on historical bug fix information. Bug Fixer constructs a Developer Component Bug  DCB  network, which models the relationship between developers and source code components, as well as the relationship between the components and their associated bugs. A DCB network captures the knowledge of  "
"J Kanwal, O Maqbool",2012,Bug prioritization to facilitate bug report triage,47,"The large number of new bug reports received in bug repositories of software systems makes their management a challenging task. Handling these reports manually is time consuming, and often results in delaying the resolution of important bugs. To address this issue, a recommender may be developed which automatically prioritizes the new bug reports. In this paper, we propose and evaluate a classification based approach to build such a recommender. We use the Na ve Bayes and Support Vector Machine  SVM  classifiers, and present a comparison to evaluate which classifier performs better in terms of accuracy. Since a bug report contains both categorical and text features, another evaluation we perform is to determine the combination of features that better determines the priority of a bug. To evaluate the bug priority recommender, we use precision and recall measures and also propose two new measures, Nearest False Negatives  NFN  and Nearest False Positives  NFP , which provide insight into the results produced by precision and recall. Our findings are that the results of SVM are better than the Na ve Bayes algorithm for text features, whereas for categorical features, Na ve Bayes performance is better than SVM. The highest accuracy is achieved with SVM when categorical and text features are combined for training."
"O Baysal, R Holmes, MW Godfrey",2012,Revisiting bug triage and resolution practices,8,"Bug triaging is an error prone, tedious and time consuming task. However, little qualitative research has been done on the actual use of bug tracking systems, bug triage, and resolution processes. We are planning to conduct a qualitative study to understand the dynamics of bug triage and fixing process, as well as bug reassignments and reopens. We will study interviews conducted with Mozilla Core and Firefox developers to get insights into the primary obstacles developers face during the bug fixing process. Is the triage process flawed? Does bug review slow things down? Does approval takes too long? We will also categorize the main reasons for bug reassignments and reopens. We will then combine results with a quantitative study of Firefox bug reports, focusing on factors related to bug report edits and number of people involved in handling the bug."
"D Behl, S Handa, A Arora",2014,A bug mining tool to identify and analyze security bugs using naive bayes and tf idf,26,"Bug report contains a vital role during software development, However bug reports belongs to different categories such as performance, usability, security etc. This paper focuses on security bug and presents a bug mining system for the identification of security and non security bugs using the term frequency inverse document frequency  TF IDF  weights and na ve bayes. We performed experiments on bug report repositories of bug tracking systems such as bugzilla and debugger. In the proposed approach we apply text mining methodology and TF IDF on the existing historic bug report database based on the bug s description to predict the nature of the bug and to train a statistical model for manually mislabeled bug reports present in the database. The tool helps in deciding the priorities of the incoming bugs depending on the category of the bugs i.e. whether it is a security bug report or a non security bug report, using na ve bayes. Our evaluation shows that our tool using TF IDF is giving better results than the na ve bayes method."
"J Uddin, R Ghazali, MM Deris, R Naseem ",2017,A survey on bug prioritization,26,"Daily large number of bug reports are received in large open and close source bug tracking systems. Dealing with these reports manually utilizes time and resources which leads to delaying the resolution of important bugs. As an important process in software maintenance, bug triaging process carefully analyze these bug reports to determine, for example, whether the bugs are duplicate or unique, important or unimportant, and who will resolve them. Assigning bug reports based on their priority or importance may play an important role in enhancing the bug triaging process. The accurate and timely prioritization and hence resolution of these bug reports not only improves the quality of software maintenance task but also provides the basis to keep particular software alive. In the past decade, various studies have been conducted to prioritize bug reports using data mining techniques like classification, information retrieval and clustering that can overcome incorrect prioritization. Due to their popularity and importance, we survey the automated bug prioritization processes in a systematic way. In particular, this paper gives a small theoretical study for bug reports to motivate the necessity for work on bug prioritization. The existing work on bug prioritization and some possible problems in working with bug prioritization are summarized."
"N Goyal, N Aggarwal, M Dutta",2015,A novel way of assigning software bug priority using supervised classification on clustered bugs data,4,"Bug Triaging is an important part of testing process in software development organizations. But it takes up considerable amount of time of the Bug Triager, costing time and resources of the organization. Hence it is worth while to develop an automated system to address this issue. Researchers have addressed various aspects of this by using techniques of data mining, like classification etc. Also there is a study which claims that when classification is done on the data which is previously clustered  it significantly improves its performance. In this work, this approach has been used for the first time in the field of software testing for predicting the priority of the software bugs to find if classifier performance improves when it is preceded with clustering. Using this system, clustering was performed on problem title attribute of the bugs to group similar bugs together using clustering algorithms. Classification was then applied to the clusters obtained, to assign priority to the bugs based on their attributes severity or component using classification algorithms. It was then studied that which combination of clustering and classification algorithms used provided the best results."
"P Bhattacharya, L Ulanova, I Neamtiu ",2013,An empirical analysis of bug reports and bug fixing in open source android apps,69,"Smartphone platforms and applications  apps  have gained tremendous popularity recently. Due to the novelty of the smartphone platform and tools, and the low barrier to entry for app distribution, apps are prone to errors, which affects user experience and requires frequent bug fixes. An essential step towards correcting this situation is understanding the nature of the bugs and bug fixing processes associated with smartphone platforms and apps. However, prior empirical bug studies have focused mostly on desktop and server applications. Therefore, in this paper, we perform an in depth empirical study on bugs in the Google Android smartphone platform and 24 widely used open source Android apps from diverse categories such as communication, tools, and media. Our analysis has three main thrusts. First, we define several metrics to understand the quality of bug reports and analyze the bug fix process, including developer involvement. Second, we show how differences in bug life cycles can affect the bug fix process. Third, as Android devices carry significant amounts of security sensitive information, we perform a study of Android security bugs. We found that, although contributor activity in these projects is generally high, developer involvement decreases in some projects, similarly, while bug report quality is high, bug triaging is still a problem. Finally, we observe that in Android apps, security bug reports are of higher quality but get fixed slower than non security bugs. We believe that the findings of our study could potentially benefit both developers and users of Android apps."
"J Tucek, S Lu, C Huang, S Xanthos ",2007,Triage: diagnosing production run failures at the user s site,171,"Diagnosing production run failures is a challenging yet importanttask. Most previous work focuses on offsite diagnosis, i.e.development site diagnosis with the programmers present. This is insufficient for production run failures as:  1  it is difficult to reproduce failures offsite for diagnosis   2  offsite diagnosis cannot provide timely guidance for recovery or security purposes   3 it is infeasible to provide a programmer to diagnose every production run failure  and  4  privacy concerns limit the release of information e.g. coredumps  to programmers. To address production run failures, we propose a system, called Triage, that automatically performs onsite software failure diagnosis at the very moment of failure. It provides a detailed diagnosis report, including the failure nature, triggering conditions, related code and variables, the fault propagation chain, and potential fixes. Triage achieves this by leveraging lightweight reexecution support to efficiently capture the failure environment and repeatedly replay the moment of failure, and dynamically using different diagnosis techniques analyze an occurring failure. Triage employs afailure diagnosis protocol that mimics the steps a human takes in debugging. This extensible protocol provides a framework to enable the use of various existing and new diagnosis techniques. We also propose a new failure diagnosis technique, delta analysis, to identify failure related conditions, code, and variables. We evaluate these ideas in real system experiments with 10 real software failures from 9 open source applications including four servers. Triage accurately diagnoses the evaluated failures, providing likely root causes and even the fault propagation chain, while keeping normal run overhead to under 5 . Finally, our user study of the diagnosis and repair of real bugs shows that Triagesaves time  99.99  confidence , reducing the total time to fix by almost half."
"A Lamkanfi, J P rez, S Demeyer",2013,The eclipse and mozilla defect tracking dataset: a genuine dataset for mining bug information,44,"The analysis of bug reports is an important subfield within the mining software repositories community. It explores the rich data available in defect tracking systems to uncover interesting and actionable information about the bug triaging process. While bug data is readily accessible from systems like Bugzilla and JIRA, a common database schema and a curated dataset could significantly enhance future research because it allows for easier replication. Consequently, in this paper we propose the Eclipse and Mozilla Defect Tracking Dataset, a representative database of bug data, filtered to contain only genuine defects  i.e., no feature requests  and designed to cover the whole bug triage life cycle  i.e., store all intermediate actions . We have used this dataset ourselves for predicting bug severity, for studying bug fixing time and for identifying erroneously assigned components. Sharing these data with the rest of the community will allow for reproducibility, validation and comparison of the results obtained in bug report analyses and experiments."
"D Wijayasekara, M Manic, JL Wright ",2012,Mining bug databases for unidentified software vulnerabilities,36,"Identifying software vulnerabilities is becoming more important as critical and sensitive systems increasingly rely on complex software systems. It has been suggested in previous work that some bugs are only identified as vulnerabilities long after the bug has been made public. These vulnerabilities are known as hidden impact vulnerabilities. This paper discusses existing bug data mining classifiers and present an analysis of vulnerability databases showing the necessity to mine common publicly available bug databases for hidden impact vulnerabilities. We present a vulnerability analysis from January 2006 to April 2011 for two well known software packages: Linux kernel and MySQL. We show that 32   Linux  and 62   MySQL  of vulnerabilities discovered in this time period were hidden impact vulnerabilities. We also show that the percentage of hidden impact vulnerabilities has increased from 25  to 36  in Linux and from 59  to 65  in MySQL in the last two years. We then propose a hidden impact vulnerability identification methodology based on text mining classifier for bug databases. Finally, we discuss potential challenges faced by a development team when using such a classifier."
SS Alqahtani,2019,Automated Extraction of Security Concerns from Bug Reports,0,"Issue tracker repositories contain a wealth of textual information including bug reports that capture information, often implicit, about Information Security  IS  concerns and vulnerabilities associated with certain issues. Deriving an approach to extract such security concerns from bug reports can yield several benefits, such as bug management  e.g., prioritization  or bug triage. Existing research on Information Extraction  IE  for extracting knowledge from bug reports has mainly focused on supervised learning, which requires a significant amount of human labor in preparing a training corpus. In this paper, we explore a fully automated approach that can extract security concepts  tags  from bug reports without the need for manual training data. This approach can automatically identify and classify bug reports based on their security concepts and textual similarities. In addition, we further enrich these tags with meaningful and representative security names derived from the security domain."
"D Zou, Z Deng, Z Li, H Jin",2018,Automatically identifying security bug reports via multitype features analysis,1,"Bug tracking systems are widely used by software developers to manage bug reports. Since it is time consuming and costly to fix all the bugs, developers usually pay more attention to the bugs with higher impact, such as security bugs  i.e., vulnerabilities  which can be exploited by malicious users to launch attacks and cause great damages. However, manually identifying security bug reports from millions of reports in bug tracking systems is difficult and error prone. Furthermore, existing automated identification approaches to security bug reports often incur many false negatives, causing a hidden danger to the computer system. To address this important problem, we present an automatic security bug reports identification model via multitype features analysis, dubbed Security Bug Report Identifier  SBRer . Specifically, we make use of multiple kinds of information contained in a bug report, including meta features and textual features, to automatically identify the security bug reports via natural language processing and machine learning techniques. The experimental results show that SBRer with imbalanced data processing can successfully identify the security bug reports with a much higher precision of 99.4  and recall of 79.9  compared to existing work."
"V Guana, F Rocha, A Hindle ",2012,Do the stars align? Multidimensional analysis of Android s layered architecture,22,"In this paper we mine the Android bug tracker repository and study the characteristics of the architectural layers of the Android system. We have identified the locality of the Android bugs in the architectural layers of the its infrastructure, and analysed the bug lifetime patterns in each one of them. Additionally, we mined the bug tracker reporters and classified them according to its social centrality in the Android bug tracker community. We report three interesting findings, firstly while some architectural layers have a diverse interaction of people, attracting not only non central reporters but highly important ones, other layers are mostly captivating for peripheral actors. Second, we exposed that even the bug lifetime is similar across the architectural layers, some of them have higher bug density and differential percentages of unsolved bugs. Finally, comparing the popularity distribution between layers, we have identified one particular layer that is more important to developers and users alike."
"Y Tian, D Lo, X Xia, C Sun",2015,Automated prediction of bug report priority using multi factor analysis,59,"Bugs are prevalent. To improve software quality, developers often allow users to report bugs that they found using a bug tracking system such as Bugzilla. Users would specify among other things, a description of the bug, the component that is affected by the bug, and the severity of the bug. Based on this information, bug triagers would then assign a priority level to the reported bug. As resources are limited, bug reports would be investigated based on their priority levels. This priority assignment process however is a manual one. Could we do better? In this paper, we propose an automated approach based on machine learning that would recommend a priority level based on information available in bug reports. Our approach considers multiple factors, temporal, textual, author, related report, severity, and product, that potentially affect the priority level of a bug report. These factors are extracted as features which are then used to train a discriminative model via a new classification algorithm that handles ordinal class labels and imbalanced data. Experiments on more than a hundred thousands bug reports from Eclipse show that we can outperform baseline approaches in terms of average F measure by a relative improvement of up to 209  ."
"I Chawla, SK Singh",2014,Automatic bug labeling using semantic information from LSI,7,"Most open source projects provide a defect tracking system, where users, developers, testers can directly report the problems. The fields provided in the bug report help triager and debugger to understand the problem better. They also help in other tasks like accurate assessment of priority and severity of bugs, identification of appropriate developer to resolve bugs etc. Label field in the bug report is one such field. It has been observed that in many bug repositories, the label field is either not present or is incorrectly assigned. There is a need for automatic bug labeling so that bug reports could be made more informative. This paper presents an automated technique for bug labeling using TF IDF and LSI. Experimental study shows that there is improvement in results with the addition of semantically similar words obtained from LSI in conjunction with the terms extracted using TF IDF. Using LSI along with TF IDF, we achieved 61.5  accuracy for the polish bug reports and 62.8  accuracy for security bug reports as compared to 53.8  accuracy for polish and 61  for security bug reports from using TF IDF alone."
"A Bansal, R Malhotra, K Raje",2016,Analyzing and assessing the security related defects,4,"The use of the Internet has become an integral part of everyone s life. Due to this, the introduction of virus and other malicious crackers is increasing everyday. This in turn leads to the introduction of defects which adversely affect the security. Thus, protecting vital information in this cyber world is not an easy task. We need to deal with security related defects to ensure failure free and smooth functioning of the software. Thus, in this paper, we intend to study and analyze various aspects of security related defects by analyzing the defect reports available in various open source software repositories. Besides this, prediction models can also be constructed which can be used by researchers and practitioners to predict various aspects of security   related defects. Such prediction models are especially beneficial for large scale systems, where testing experts need to focus their attention and resources to the problem areas of the system under development. Thus, application of software prediction models in the early phases of the software life cycle contributes to efficient defect removal and results in delivering more reliable and better quality software products. Empirical studies lack the use of proper research methodology and thus result in reporting inconsistent results. This study will review the sequence of steps followed in the research process for carrying empirical and replicated studies. The steps include  a  literature survey and definition of variables  b  data collection  c  report findings using statistical and machine learning techniques  d  analyzing performance measures for evaluating the performance of the predicted models and  e  interpretation of the obtained results for developing a software prediction model. These steps are explained with the help of experimental public domain data set. In addition, the paper provides an overview of repositories for mining software engineering data, tools for analyzing this data and various categories of machine learning methods. It also discusses existing research avenues and provides future research directions in this area."
"MN Pushpalatha, M Mrunalini",2016,Predicting the severity of bug reports using classification algorithms,5,"Bug triaging is the process of prioritizing the bug reports based on the severity and is driven by the business needs and available resources. Majority times, only few of the reported bugs are selected to be fixed. The selected bugs are prioritized  ordered  based on their severity  e.g. the bug inhibits an important feature of the product, the bug affects a large number of users  and then fixed according to their priority. If the severity is assigned incorrectly then time and resources may be wasted to fix that bug. Hence there is a need for new techniques to avoid this misuse of resources. In this paper, bagging ensemble method is used for predicting the severity of bug reports. Also, bagging ensemble method is compared with C4.5 classifier. The results have shown that bagging ensemble method gives better accuracy compared to C4.5 general classifier on the given dataset."
"XL Yang, D Lo, X Xia, Q Huang, JL Sun",2017,High impact bug report identification with imbalanced learning strategies,22,"In practice, some bugs have more impact than others and thus deserve more immediate attention. Due to tight schedule and limited human resources, developers may not have enough time to inspect all bugs. Thus, they often concentrate on bugs that are highly impactful. In the literature, high impact bugs are used to refer to the bugs which appear at unexpected time or locations and bring more unexpected effects  i.e., surprise bugs , or break pre existing functionalities and destroy the user experience  i.e., breakage bugs . Unfortunately, identifying high impact bugs from thousands of bug reports in a bug tracking system is not an easy feat. Thus, an automated technique that can identify high impact bug reports can help developers to be aware of them early, rectify them quickly, and minimize the damages they cause. Considering that only a small proportion of bugs are high impact bugs, the identification of high impact bug reports is a difficult task. In this paper, we propose an approach to identify high impact bug reports by leveraging imbalanced learning strategies. We investigate the effectiveness of various variants, each of which combines one particular imbalanced learning strategy and one particular classification algorithm. In particular, we choose four widely used strategies for dealing with imbalanced data and four state of the art text classification algorithms to conduct experiments on four datasets from four different open source projects. We mainly perform an analytical study on two types of high impact bugs, i.e., surprise bugs and breakage bugs. The results show that different variants have different performances, and the best performing variants SMOTE  synthetic minority over sampling technique    KNN  K nearest neighbours  for surprise bug identification and RUS  random under sampling    NB  naive Bayes  for breakage bug identification outperform the F1 scores of the two state of the art approaches by Thung et al. and Garcia and Shihab."
"L Tan, C Liu, Z Li, X Wang, Y Zhou, C Zhai",2014,Bug characteristics in open source software,100,"To design effective tools for detecting and recovering from software failures requires a deep understanding of software bug characteristics. We study software bug characteristics by sampling 2,060 real world bugs in three large, representative open source projects the Linux kernel, Mozilla, and Apache. We manually study these bugs in three dimensions root causes, impacts, and components. We further study the correlation between categories in different dimensions, and the trend of different types of bugs. The findings include:  1  semantic bugs are the dominant root cause. As software evolves, semantic bugs increase, while memory related bugs decrease, calling for more research effort to address semantic bugs   2  the Linux kernel operating system  OS  has more concurrency bugs than its non OS counterparts, suggesting more effort into detecting concurrency bugs in operating system code  and  3  reported security bugs are increasing, and the majority of them are caused by semantic bugs, suggesting more support to help developers diagnose and fix security bugs, especially semantic security bugs. In addition, to reduce the manual effort in building bug benchmarks for evaluating bug detection and diagnosis tools, we use machine learning techniques to classify 109,014 bugs automatically."
"PJ Guo, T Zimmermann, N Nagappan ",2011,  Not my bug!  and other reasons for software bug report reassignments,123,"Bug reporting fixing is an important social part of the soft ware development process. The bug fixing process inher ently has strong inter personal dynamics at play, especially in how to find the optimal person to handle a bug report. Bug report reassignments, which are a common part of the bug fixing process, have rarely been studied. In this paper, we present a large scale quantitative and qualitative analysis of the bug reassignment process in the Microsoft Windows Vista operating system project. We quantify social interactions in terms of both useful and harmful reassignments. For instance, we found that reassignments are useful to determine the best person to fix a bug, contrary to the popular opinion that reassignments are always harmful. We categorized five primary reasons for reassignments: finding the root cause, determining ownership, poor bug report quality, hard to determine proper fix, and workload balancing. We then use these findings to make recommendations for the design of more socially aware bug tracking systems that can overcome some of the inefficiencies we observed in our study."
"M Alenezi, S Banitaan",2013,Bug reports prioritization: Which features and classifier to use?,24,"Large open source bug tracking systems receives large number of bug reports daily. Managing these huge numbers of incoming bug reports is a challenging task. Dealing with these reports manually consumes time and resources which leads to delaying the resolution of important bugs which are crucial and need to be identified and resolved earlier. Bug triaging is an important process in software maintenance. Some bugs are important and need to be fixed right away, whereas others are minor and their fixes could be postponed until resources are available. Most automatic bug assignment approaches do not take the priority of bug reports in their consideration. Assigning bug reports based on their priority may play an important role in enhancing the bug triaging process. In this paper, we present an approach to predict the priority of a reported bug using different machine learning algorithms namely Naive Bayes, Decision Trees, and Random Forest. We also investigate the effect of using two feature sets on the classification accuracy. We conduct experimental evaluation using open source projects namely Eclipse and Fire fox. The experimental evaluation shows that the proposed approach is feasible in predicting the priority of bug reports. It also shows that feature set 2 outperformsfeature set 1. Moreover, both Random Forests and Decision Trees outperform Naive Bayes."
"N Sreenivas, SJ Saritha",2017,Enhancement towards efficient bug triage with software data reducing methods,0,"Bug Triage is most important task of fixing bugs in computer code development organizations. It s methodology of allocating an accurate developer for fixing a bug. Sometimes in computer code implementing new bugs square measure manually triaged consummate developer. Thanks to the big range of bugs   also lack of experience of all bugs, the manual bug sorting is affluent in time price and low in acceptance. To say no the costly price in manual bug sorting, an automatic bug sorting approach is employed. For bug sorting information reduction techniques is employed to construct a tiny low scale and high superiority bug information by removing bug reports and words that square measure redundant or not useful. Thus we have tendency to square measure exploitation instance choice and have choice at same time with historical bug information sets. We ve got other a brand new module here as feedback session. During this system we are going to take the traditional feedback from the developer when finishing the bug."
CL Huntley,2006,A developmental view of system security,11,"Security policy can t be timeless, static, and universal. Security is more of a developmental problem than a technical one. Security should be integrated into an organization in such a way as to enhance and safeguard each facet in the least intrusive yet most effective way possible at a given time. Gradually, as the organization and the technology it uses  "
"CC Yeh, HL Lu, YH Lee, WS Chou ",2017,CRAXTriage: A coverage based triage system,0,"Software is getting complicated due to the changing needs and flourishing development of software industry. To better improve software quality, we have to find the major reasons which cause the program crash. However, debugging by software developer is not an efficient method, especially in large software. Many automated tools are developed to enhance the fault localization efficiency and reduce the maintenance cost. Most researches focus on improving the software testing process, and the primary triage method is based on the stack trace hash  e.g., smartfuzz, basic fuzzing framework and Failure Observation engine , and is unchanged for a long time. Therefore, we propose a new triage method based on binary block coverage. Our triage method is designed by analyzing the binary level coverage results, on every time the input causes the program crash. For the same crash input, we also use traditional stack trace hash method to contrast the flaws with our method. Our experiment results reveal that our proposed method based on code coverage exhibits better triages in terms of the number of unique bugs identified and correct classifications of faults."
"P Schugerl, J Rilling, P Charland",2008,Mining bug repositories a quality assessment,20,"The process of evaluating, classifying, and assigning bugs to programmers is a difficult and time consuming task which greatly depends on the quality of the bug report itself. It has been shown that the quality of reports originating from bug trackers or ticketing systems can vary significantly. In this research, we apply information retrieval  IR  and natural language processing  NLP  techniques for mining bug repositories. We focus particularly on measuring the quality of the free form descriptions submitted as part of bug reports used by open source bug trackers. Properties of natural language influencing the report quality are automatically identified and applied as part of a classification task. The results from the automated quality assessment are used to populate and enrich our existing software engineering ontology to support a further analysis of the quality and maturity of bug trackers."
"R Jaiswal, M Sahare, U Lilhore",2018,Genetic Approach based Bug Triage for Sequencing the Instance and Features,0,"In software industry analyzing bug by various tester and developer is a costly approach. So collecting these bug reports and triage is done manually which consume time with high rate of error. Here proposed work has focus on this triage of the bug reports by reducing the dataset size. In order to reduce cost of bug triage proper sequencing of the instance and feature selection is done. Here instance and feature selection are clustered by using list of words, keywords and bug id as fitness function parameters. Two stage learning genetic algorithm named as teacher learning based optimization was used for clustering. As genetic algorithms are unsupervised learning approach, so new set bug report triage is adopt by the proposed work. Experiment is done on real dataset of bug reports. Result shows that proposed work is better on precision value by 38.5  while execution time was reduce by 29.2  as compared with existing procedures."
"JR Goodall, H Radwan, L Halseth",2010,Visual analysis of code security,34,"To help increase the confidence that software is secure, researchers and vendors have developed different kinds of automated software security analysis tools. These tools analyze software for weaknesses and vulnerabilities, but the individual tools catch different vulnerabilities and produce voluminous data with many false positives. This paper describes a system that brings together the results of disparate software analysis tools into a visual environment to support the triage and exploration of code vulnerabilities. Our system allows software developers to explore vulnerability results to uncover hidden trends, triage the most important code weaknesses, and show who is responsible for introducing software vulnerabilities. By correlating and normalizing multiple software analysis tools  data, the overall vulnerability detection coverage of software is increased. A visual overview and powerful interaction allows the user to focus attention on the most pressing vulnerabilities within huge volumes of data, and streamlines the secure software development workflow through integration with development tools."
"S Mostafa, B Findley, N Meng ",2019,SAIS: Self Adaptive Identification of Security Bug Reports,0,"Among various bug reports  BRs , security bug reports  SBRs  are unique because they require immediate concealment and fixes. When SBRs are not identified in time, attackers can exploit the vulnerabilities. Prior work identifies SBRs via text mining, which requires a predefined keyword list and trains a classifier with known SBRs and non security bug reports  NSBRs . The former approach is not reliable, because  1  as the contexts of security vulnerabilities and terminology of SBRs change over time, the predefined list will become out dated  and  2  users may have insufficient SBRs for training. We introduce a semi supervised learning based approach,  tool, to adaptively and reliably identify SBRs. Given a project s BRs containing some labeled SBRs, many more NSBRs, and unlabeled BRs, SAIS iteratively mines keywords, trains a classifier based on the keywords from the labeled data, classifies unlabeled BRs, and augments its training data with the newly labeled BRs. Our evaluation shows that SAIS is useful for identifying SBRs."
"S Gujral, G Sharma, S Sharma",2015,Classifying bug severity using dictionary based approach,9,Bug tracking system allows user to report bugs that they encounter while operating the software. These bugs are then received by developers and they resolve these bugs according to their severity level. This task of assigning severity level is manual task that need expertise of assessing the severity level of reported bug. But if these reported bugs are large in number then manual process to assess severity level of bugs becomes very hectic. So there should be an automatic process to classify it so that bugs that need immediate fixation get resolved early. A few attempts have been made by researchers to automate the task. The approach followed in this paper has made an attempt to automate the bug severity classification using text mining technique and Na ve Bayes Multinomial classifier. This paper further proposes an approach of making this task more efficient using dictionary of bug terms.
"M Pereira, A Kumar ",2019,Identifying Security Bug Reports Based Solely on Report Titles and Noisy Data,0,"Identifying security bug reports  SBRs  is a vital step in the software development life cycle. In supervised machine learning based approaches, it is usual to assume that entire bug reports are available for training and that their labels are noise free. To the best of our knowledge, this is the first study to show that accurate label prediction is possible for SBRs even when solely the title is available and in the presence of label noise."
O Chaparro,2017,"Improving bug reporting, duplicate detection, and localization",5,"Software developers rely on essential textual information from bug reports  such as Observed Behavior, Expected Behavior, and Steps to Reproduce  to triage and fix software bugs. Unfortunately, while relevant and useful, this information is often missing, incomplete, superficial, ambiguous, or complex to follow. Low quality content in bug reports causes delay and extra effort on bug triage and fixing. Current technology and research are insufficient to support users and developers on providing high quality content in bug reports. Our research is intended to fill in this gap, as it aims at improving:  1  the quality of natural language content in bug reports, and  2  the accuracy of Text Retrieval  TR based bug localization and duplicate detection. To achieve such goals, our research will identify, enforce, and leverage the discourse that reporters use to describe software bugs."
MR Karim,2019,Key features recommendation to improve bug reporting,1,"Bug reports are the primary means through which developers triage and fix bugs. To achieve this effectively, bug reports need to clearly describe those features that are important for the developers. However, previous studies have found that reporters do not always provide such features. Therefore, we first perform an exploratory study to identify the key features that reporters frequently miss in their initial bug report submissions. Then, we plan to propose an automatic approach for supporting reporters to make a good bug report. For our initial studies, we manually examine bug reports of five large scale projects from two ecosystems such as Apache  Camel, Derby, and Wicket  and Mozilla  Firefox and Thunderbird . As initial results, we identify five key features that reporters often miss in their initial bug reports and developers require them for fixing bugs. We build and evaluate classification models using four different text classification techniques. The evaluation results show that our models can effectively predict the key features. Our ongoing research focuses on developing an automatic features recommendation model to improve the contents of bug reports."
"Y Kashiwa, H Yoshiyuki, Y Kukita ",2014,A pilot study of diversity in high impact bugs,8,"Since increasing complexity and scale of modern software products imposes tight scheduling and resource allocations on software development projects, a project manager must carefully triage bugs to determine which bug should be necessarily fixed before shipping. Although in the field of Mining Software Repositories  MSR  there are many promising approaches to predicting, localizing, and triaging bugs, most of them do not consider impacts of each bug on users and developers but rather treat all bugs with equal weighting, excepting a few studies on high impact bugs including security, performance, blocking, and so forth. To make MSR techniques more actionable and effective in practice, we need deeper understandings of high impact bugs. In this paper we report our pilot study on high impact bugs, which classifies bugs reported to four open source projects into six types of high impact bugs."
"M Woo, SK Cha, S Gottlieb, D Brumley",2013,Scheduling black box mutational fuzzing,106,"Black box mutational fuzzing is a simple yet effective technique to find bugs in software. Given a set of program seed pairs, we ask how to schedule the fuzzings of these pairs in order to maximize the number of unique bugs found at any point in time. We develop an analytic framework using a mathematical model of black box mutational fuzzing and use it to evaluate 26 existing and new randomized online scheduling algorithms. Our experiments show that one of our new scheduling algorithms outperforms the multi armed bandit algorithm in the current version of the CERT Basic Fuzzing Framework  BFF  by finding 1.5x more unique bugs in the same amount of time."
"Y Tian, D Lo, C Sun",2012,Information retrieval based nearest neighbor classification for fine grained bug severity prediction,126,"Bugs are prevalent in software systems. Some bugs are critical and need to be fixed right away, whereas others are minor and their fixes could be postponed until resources are available. In this work, we propose a new approach leveraging information retrieval, in particular BM25 based document similarity function, to automatically predict the severity of bug reports. Our approach automatically analyzes bug reports reported in the past along with their assigned severity labels, and recommends severity labels to newly reported bug reports. Duplicate bug reports are utilized to determine what bug report features, be it textual, ordinal, or categorical, are important. We focus on predicting fine grained severity labels, namely the different severity labels of Bugzilla including: blocker, critical, major, minor, and trivial. Compared to the existing state of the art study on fine grained severity prediction, namely the work by Menzies and Marcus, our approach brings significant improvement."
"G Catolino, F Palomba, A Zaidman ",2019,"Not all bugs are the same: Understanding, characterizing, and classifying bug types",4," A novel taxonomy of type of bugs composed of 9 categories. Analysis of the performance of a bug type classification model. A new public dataset composed of 1280 bug reports extracted from 119 projects. Results show high value of F Measure and AUC ROC  64  and 74 , respectively . A novel taxonomy of type of bugs composed of 9 categories. Analysis of the performance of a bug type classification model. A new public dataset composed of 1280 bug reports extracted from 119 projects. Results show high value of F Measure and AUC ROC  64  and 74 , respectively . Modern version control systems, e.g., GitHub, include bug tracking mechanisms that developers can use to highlight the presence of bugs. This is done by means of bug reports, i.e., textual descriptions reporting the problem and the steps that led to a failure. In past and recent years, the research community deeply investigated methods for easing bug triage, that is, the process of assigning the fixing of a reported bug to the most qualified developer. Nevertheless, only a few studies have reported on how to support developers in the process of understanding the type of a reported bug, which is the first and most time consuming step to perform before assigning a bug fix operation. In this paper, we target this problem in two ways: first, we analyze 1280 bug reports of 119 popular projects belonging to three ecosystems such as Mozilla, Apache, and Eclipse, with the aim of building a taxonomy of the types of reported bugs  then, we devise and evaluate an automated classification model able to classify reported bugs according to the defined taxonomy. As a result, we found nine main common bug types over the considered systems. Moreover, our model achieves high F Measure and AUC ROC  64  and 74  on overall, respectively ."
"DC Das, MR Rahman",2018,Security and Performance Bug Reports Identification with Class Imbalance Sampling and Feature Selection,0,"Nowadays, software projects receive a huge number of bug reports daily. Among them, security and performance bug reports are higher priority to software developers and users. So, rapid identification of security and performance bug reports as soon as these are reported is mandatory. But bug tracking systems do not provide any mechanism to isolate them from the collection of bug reports. In this paper, we have proposed a learning based approach to identify security and performance bug reports addressing class bias and feature skew phenomenon. We have proposed two separate classification models namely Sec Model and Perf Model, where the former classifies a bug report as security or non security bug report and the latter classifies as performance or non performance bug report. We have experimented our approach on four datasets of bug reports of four software projects  Ambari, Camel, Derby and Wicket. We have evaluated the performance of our two models in terms of area under curve receiver operating characteristics curve  AUC . The average AUC values of Sec Model and Perf Model are 0.67 and 0.71 respectively."
"E Murphy Hill, T Zimmermann, C Bird ",2014,The design space of bug fixes and how developers navigate it,40,"When software engineers fix bugs, they may have several options as to how to fix those bugs. Which fix they choose has many implications, both for practitioners and researchers: What is the risk of introducing other bugs during the fix? Is the bug fix in the same code that caused the bug? Is the change fixing the cause or just covering a symptom? In this paper, we investigate alternative fixes to bugs and present an empirical study of how engineers make design choices about how to fix bugs. We start with a motivating case study of the Pex4Fun environment. Then, based on qualitative interviews with 40 engineers working on a variety of products, data from six bug triage meetings, and a survey filled out by 326 Microsoft engineers and 37 developers from other companies, we found a number of factors, many of them non technical, that influence how bugs are fixed, such as how close to release the software is. We also discuss implications for research and practice, including how to make bug prediction and localization more accurate."
"L Yu, C Kong, L Xu, J Zhao, HH Zhang",2008,Mining bug classifier and debug strategy association rules for web based applications,6,"The paper uses data mining approaches to classify bug types and excavate debug strategy association rules for Web based applications. Chi square algorithm is used to extract bug features, and SVM to model bug classifier achieving more than 70  predication accuracy on average. Debug strategy association rules accumulate bug fixing knowledge and experiences regarding to typical bug types, and can be applied repeatedly, thus improving the bug fixing efficiency. With 575 training data, three debug strategy association rules are unearthed."
"S Lal, A Sureka",2012,Comparison of seven bug report types: A case study of google chrome browser project,17,"Bug reports submitted to an issue tracking system can belong to different categories such as crash, regression, security, cleanup, polish, performance and usability. A deeper understanding of the properties and features of various categories of bug reports can have implications in improving software maintenance processes, tools and practices. We identify several metrics and characteristics serving as dimensions on which various types of bug reports can be compared. We perform a case study on Google Chromium Browser open source project and conduct a series of experiments to calculate various metrics. We present a characterization study comparing different types of bug reports on metrics such as: statistics on close time, number of stars, number of comments, discriminatory and frequent words for each class, entropy across reporters, entropy across component, opening and closing trend, continuity and debugging efficiency performance characteristics. The calculated metrics shows the similarities and differences on various dimensions for seven different types of bug reports."
"N Ayewah, W Pugh, JD Morgenthaler, J Penix ",2007,Using findbugs on production software,65,"This poster will present our experiences using FindBugs in production software development environments, including both open source efforts and Google s internal code base. We summarize the defects found, describe the issue of real but trivial defects, and discuss the integration of FindBugs into Google s Mondrian code review system."
"J Tong, L Ying, Y Xiaoyong, T Hongyan ",2015,Characterizing and predicting bug assignment in openstack,3,"Open source software is becoming increasingly important in cloud computing. However, many cloud computing systems suffer from software bugs that cause significant dependability issues. Bug assignment and fixing are crucial parts of software maintenance to improve dependability. In this paper, we conduct an empirical study of 42,880 bug reports from OpenStack bug repository. We study the characteristics  e.g., distribution of bugs, distribution of assignees  of bug assignments in OpenStack and find the bug assignment pattern which we call as long tail. The findings can support the follow up research on improving efficiency of bug assignment, that is, we propose a prediction method based on long tail model, and experimentally evaluate this method by applying it to OpenStack bug assignment."
"M Ohira, Y Kashiwa, Y Yamatani ",2015,A dataset of high impact bugs: Manually classified issue reports,27,"The importance of supporting test and maintenance activities in software development has been increasing, since recent software systems have become large and complex. Although in the field of Mining Software Repositories  MSR  there are many promising approaches to predicting, localizing, and triaging bugs, most of them do not consider impacts of each bug on users and developers but rather treat all bugs with equal weighting, excepting a few studies on high impact bugs including security, performance, blocking, and so forth. To make MSR techniques more actionable and effective in practice, we need deeper understandings of high impact bugs. In this paper we introduced our dataset of high impact bugs which was created by manually reviewing four thousand issue reports in four open source projects  Ambari, Camel, Derby and Wicket ."
"R Vieira, A da Silva, L Rocha, JP Gomes",2019,From Reports to Bug Fix Commits: A 10 Years Dataset of Bug Fixing Activity from 55 Apache s Open Source Projects,0,"Bugs appear in almost any software development. Solving all or at least a large part of them requires a great deal of time, effort, and budget. Software projects typically use issue tracking systems as a way to report and monitor bug fixing tasks. In recent years, several researchers have been conducting bug tracking analysis to better understand the problem and thus provide means to reduce costs and improve the efficiency of the bug fixing task. In this paper, we introduce a new dataset composed of more than 70,000 bug fix reports from 10 years of bug fixing activity of 55 projects from the Apache Software Foundation, distributed in 9 categories. We have mined this information from Jira issue track system concerning two different perspectives of reports with closed resolved status: static  the latest version of reports  and dynamic  the changes that have occurred in reports over time . We also extract information from the commits  if they exist  that fix such bugs from their respective version control system  Git . We also provide a change analysis that occurs in the reports as a way of illustrating and characterizing the proposed dataset. Once the data extraction process is an error prone nontrivial task, we believe such initiatives like this could be useful to support researchers in further more detailed investigations."
"T Zimmermann, N Nagappan, PJ Guo ",2012,Characterizing and predicting which bugs get reopened,132,"Fixing bugs is an important part of the software development process. An underlying aspect is the effectiveness of fixes: if a fair number of fixed bugs are reopened, it could indicate instability in the software system. To the best of our knowledge there has been on little prior work on understanding the dynamics of bug reopens. Towards that end, in this paper, we characterize when bug reports are reopened by using the Microsoft Windows operating system project as an empirical case study. Our analysis is based on a mixed methods approach. First, we categorize the primary reasons for reopens based on a survey of 358 Microsoft employees. We then reinforce these results with a large scale quantitative study of Windows bug reports, focusing on factors related to bug report edits and relationships between people involved in handling the bug. Finally, we build statistical models to describe the impact of various metrics on reopening bugs ranging from the reputation of the opener to how the bug was found."
"F Thung, D Lo, L Jiang, F Rahman ",2012,To what extent could we detect field defects? an empirical study of false negatives in static bug finding tools,32,"Software defects can cause much loss. Static bug finding tools are believed to help detect and remove defects. These tools are designed to find programming errors  but, do they in fact help prevent actual defects that occur in the field and reported by users? If these tools had been used, would they have detected these field defects, and generated warnings that would direct programmers to fix them? To answer these questions, we perform an empirical study that investigates the effectiveness of state of the art static bug finding tools on hundreds of reported and fixed defects extracted from three open source programs: Lucene, Rhino, and AspectJ. Our study addresses the question: To what extent could field defects be found and detected by state of the art static bug finding tools? Different from past studies that are concerned with the numbers of false positives produced by such tools, we address an orthogonal issue on the numbers of false negatives. We find that although many field defects could be detected by static bug finding tools, a substantial proportion of defects could not be flagged. We also analyze the types of tool warnings that are more effective in finding field defects and characterize the types of missed defects."
"BB Madan, K Go eva Popstojanova ",2004,A method for modeling and quantifying the security attributes of intrusion tolerant systems,329,"Complex software and network based information server systems may exhibit failures. Quite often, such failures may not be accidental. Instead some failures may be caused by deliberate security intrusions with the intent ranging from simple mischief, theft of confidential information to loss of crucial and possibly life saving services. Not only it is important to prevent and or tolerate security intrusions, it is equally important to treat security as a QoS attribute at par with other QoS attributes such as availability and performance. This paper deals with various issues related to quantifying the security attributes of an intrusion tolerant system, such as the SITAR system. A security intrusion and the response of an intrusion tolerant system to an attack is modeled as a random process. This facilitates the use of stochastic modeling techniques to capture the attacker behavior as well as the system s response to a security intrusion. This model is used to analyze and quantify the security attributes of the system. The security quantification analysis is first carried out for steady state behavior leading to measures like steady state availability. By transforming this model to a model with absorbing states, we compute a security measure called the  mean time  or effort  to security failure   MTTSF  and also compute probabilities of security failure due to violations of different security attributes."
"PJ Guo, T Zimmermann, N Nagappan ",2010,Characterizing and predicting which bugs get fixed: an empirical study of Microsoft Windows,243,"We performed an empirical study to characterize factors that affect which bugs get fixed in Windows Vista and Windows 7, focusing on factors related to bug report edits and relationships between people involved in handling the bug. We found that bugs reported by people with better reputations were more likely to get fixed, as were bugs handled by people on the same team and working in geographical proximity. We reinforce these quantitative results with survey feedback from 358 Microsoft employees who were involved in Windows bugs. Survey respondents also mentioned additional qualitative influences on bug fixing, such as the importance of seniority and interpersonal skills of the bug reporter. Informed by these findings, we built a statistical model to predict the probability that a new bug will be fixed  the first known one, to the best of our knowledge . We trained it on Windows Vista bugs and got a precision of 68  and recall of 64  when predicting Windows 7 bug fixes. Engineers could use such a model to prioritize bugs during triage, to estimate developer workloads, and to decide which bugs should be closed or migrated to future product versions."
"T Zimmermann, R Premraj, N Bettenburg ",2010,What makes a good bug report?,201,"In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are, at the same time, most difficult to provide for users. Such insight is helpful for designing new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports  it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. The participants of our survey also provided 175 comments on hurdles in reporting and resolving bugs. Based on these comments, we discuss several recommendations for better bug tracking systems, which should focus on engaging bug reporters, better tool support, and improved handling of bug duplicates."
"TH Chen, M Nagappan, E Shihab ",2014,An empirical study of dormant bugs,45," Over the past decade, several research efforts have studied the quality of software systems by looking at post release bugs. However, these studies do not account for bugs that remain dormant  i.e., introduced in a version of the software system, but are not found until much later  for years and across many versions. Such dormant bugs skew our under  standing of the software quality. In this paper we study dormant bugs against non dormant bugs using data from 20 different open source Apache foundation software systems. We find that 33  of the bugs introduced in a version are not reported till much later  i.e., they are reported in future versions as dormant bugs . Moreover, we find that 18.9  of the reported bugs in a version are not even introduced in that version  i.e., they are dormant bugs from prior versions . In short, the use of reported bugs to judge the quality of a specific version might be misleading. Exploring the fix process for dormant bugs, we find that they are fixed faster  median fix time of 5 days  than non  dormant bugs  median fix time of 8 days , and are fixed by more experienced developers  median commit counts of developers who fix dormant bug is 169  higher . Our results highlight that dormant bugs are different from non dormant bugs in many perspectives and that future research in software quality should carefully study and consider dormant bugs. "
"BS Neysiani, SM Babamir",2019,Improving Performance of Automatic Duplicate Bug Reports Detection using Longest Common Sequence: Introducing New Textual Features for Textual Similarity  ,0,"Automatic duplicate bug reports detection is a famous problem in mining software repositories since 2004 for software triage systems e.g. Bugzilla. Textual features are the most important type of features in similarity and duplicate detection e.g. BM25F which indicate the common term frequency in two reports. Sometimes a common sequence can show more similarity in two texts, thus new features based on longest common sequence  LCS  of two bug reports proposed in this paper as new textual features for text similarity detection. Android, Eclipse, Mozilla, and Open Office dataset are used for evaluation of proposed features and the experimental results show LCS based features are important and the accuracy, precision and recall of classifier prediction models improved 4.5, 2.5 and 2.5 percent respectively on average after using LCS and get up to 96, 98 and 97 percent respectively on average using different classifiers."
"C Le Goues, M Dewey Vogt, S Forrest ",2012,A systematic study of automated program repair: Fixing 55 out of 105 bugs for  8 each,448,"There are more bugs in real world programs than human programmers can realistically address. This paper evaluates two research questions:  What fraction of bugs can be repaired automatically?  and  How much does it cost to repair a bug automatically?  In previous work, we presented GenProg, which uses genetic programming to repair defects in off the shelf C programs. To answer these questions, we:  1  propose novel algorithmic improvements to GenProg that allow it to scale to large programs and find repairs 68  more often,  2  exploit GenProg s inherent parallelism using cloud computing resources to provide grounded, human competitive cost measurements, and  3  generate a large, indicative benchmark set to use for systematic evaluations. We evaluate GenProg on 105 defects from 8 open source programs totaling 5.1 million lines of code and involving 10,193 test cases. GenProg automatically repairs 55 of those 105 defects. To our knowledge, this evaluation is the largest available of its kind, and is often two orders of magnitude larger than previous work in terms of code or test suite size or defect count. Public cloud computing prices allow our 105 runs to be reproduced for  403  a successful repair completes in 96 minutes and costs  7.32, on average."
"SS Alqahtani, J Rilling",2017,An ontology based approach to automate tagging of software artifacts,3,"Context: Software engineering repositories contain a wealth of textual information such as source code comments, developers  discussions, commit messages and bug reports. These free form text descriptions can contain both direct and implicit references to security concerns. Goal: Derive an approach to extract security concerns from textual information that can yield several benefits, such as bug management  e.g., prioritization , bug triage or capturing zero day attack. Method: Propose a fully automated classification and tagging approach that can extract security tags from these texts without the need for manual training data. Results: We introduce an ontology based Software Security Tagger Framework that can automatically identify and classify cybersecurity related entities, and concepts in text of software artifacts. Conclusion: Our preliminary results indicate that the framework can successfully extract and classify cybersecurity knowledge captured in unstructured text found in software artifacts."
"J Zhu, M Zhou, H Mei",2016,Multi extract and multi level dataset of mozilla issue tracking history,7,"Many studies analyze issue tracking repositories to understand and support software development. To facilitate the analyses, we share a Mozilla issue tracking dataset covering a 15 year history. The dataset includes three extracts and multiple levels for each extract. The three extracts were retrieved through two channels, a front end  web user interface  UI , and a back end  official database dump  of Mozilla Bugzilla at three different times. The variations  dynamics  among extracts provide space for researchers to reproduce and validate their studies, while revealing potential opportunities for studies that otherwise could not be conducted. We provide different data levels for each extract ranging from raw data to standardized data as well as to the calculated data level for targeting specific research questions. Data retrieving and processing scripts related to each data level are offered too. By employing the multi level structure, analysts can more efficiently start an inquiry from the standardized level and easily trace the data chain when necessary  e.g., to verify if a phenomenon reflected by the data is an actual event . We applied this dataset to several published studies and intend to expand the multi level and multi extract feature to other software engineering datasets."
"A Marcus, T Menzies",2010,Software is data too,30,"Software systems are designed and engineered to process data. However, software is data too. The size and variety of today s software artifacts and the multitude of stakeholder activities result in so much data that individuals can no longer reason about all of it. We argue in this position paper that data mining, statistical analysis, machine learning, information retrieval, data integration, etc., are necessary solutions to deal with software data. New research is needed to adapt existing algorithms and tools for software engineering data and processes, and new ones will have to be created. In order for this type of research to succeed, it should be supported with new approaches to empirical work, where data and results are shared globally among researchers and practitioners. Software engineering researchers can get inspired by other fields, such as, bioinformatics, where results of mining and analyzing biological data are often stored in databases shared across the world."
"PS Kochhar, F Thung, D Lo",2014,Automatic fine grained issue report reclassification,22,"Issue tracking systems are valuable resources during software maintenance activities. These systems contain different categories of issue reports such as bug, request for improvement  RFE , documentation, refactoring, task etc. While logging issue reports into a tracking system, reporters can indicate the category of the reports. Herzig et al. Recently reported that more than 40  of issue reports are given wrong categories in issue tracking systems. Among issue reports that are marked as bugs, more than 30  of them are not bug reports. The misclassification of issue reports can adversely affects developers as they then need to manually identify the categories of various issue reports. To address this problem, in this paper we propose an automated technique that reclassifies an issue report into an appropriate category. Our approach extracts various feature values from a bug report and predicts if a bug report needs to be reclassified and its reclassified category. We have evaluated our approach to reclassify more than 7,000 bug reports from HTTP Client, Jackrabbit, Lucene Java, Rhino, and Tomcat 5 into 1 out of 13 categories. Our experiments show that we can achieve a weighted precision, recall, and F1  F measure  score in the ranges of 0.58 0.71, 0.61 0.72, and 0.57 0.71 respectively. In terms of F1, which is the harmonic mean of precision and recall, our approach can substantially outperform several baselines by 28.88 416.66 ."
"A Begel, B Simon",2008,"Novice software developers, all over again",172,"Transitions from novice to expert often cause stress and anxiety and require specialized instruction and support to enact efficiently. While many studies have looked at novice computer science students, very little research has been conducted on professional novices. We conducted a two month in situ qualitative case study of new software developers in their first six months working at Microsoft. We shadowed them in all aspects of their jobs: coding, debugging, designing, and engaging with their team, and analyzed the types of tasks in which they engage. We can explain many of the behaviors revealed by our analyses if viewed through the lens of newcomer socialization from the field of organizational man agement. This new perspective also enables us to better understand how current computer science pedagogy prepares students for jobs in the software industry. We consider the implications of this data and analysis for developing new processes for learning in both university and industrial settings to help accelerate the transition from novice to expert software developer."
"D Baca, B Carlsson",2011,Agile development with security engineering activities,61,"Agile software development has been used by industry to create a more flexible and lean software development process, i.e making it possible to develop software at a faster rate and with more agility during development. There are however concerns that the higher development pace and lack of documentation are creating less secure software. We have therefore looked at three known Security Engineering processes, Microsoft SDL, Cigatel touchpoints and Common Criteria and identified what specific security activities they performed. We then compared these activities with an Agile development process that is used in industry. Developers, from a large telecommunication manufacturer, were interviewed to learn their impressions on using these security activities in an agile development process. We produced a security enhanced Agile development process that we present in this paper. This new Agile process use activities from already established security engineering processes that provide the benefit the developers wanted but did not hinder or obstruct the Agile process in a significant way."
"R Mart , S Robles, A Mart n Campillo ",2009,Providing early resource allocation during emergencies: The mobile triage tag,78,"Quick response is critical during an emergency situation. This paper describes a system based on mobile electronic triage tags that makes victim information available at the base of operations as soon as possible, thus allowing an early medical resource allocation and immediate action. The cornerstone of the system is mobile agent technology, which allows information to be transported asynchronously and reliably from terminal to terminal and not requiring any network infrastructure at all. This novel approach is ready to be used in the worst case scenario, where only small handheld devices carried by the emergency personnel are available, but also integrates well when synchronous connections are possible, for instance when a mesh network can be created. The system has been successfully implemented, showing the feasibility of the proposal. By using this low budget system, the number of casualties during the triage stage of an emergency is expected to drop off."
"F Khomh, B Chan, Y Zou ",2011,An entropy evaluation approach for triaging field crashes: A case study of mozilla firefox,48,"A crash is an unexpected termination of an application during normal execution. Crash reports record stack traces and run time information once a crash occurs. A group of similar crash reports represents a crash type. The triaging of crash types is critical to shorten the development and maintenance process. Crash triaging process decides the priority of crash types to be fixed. The decision typically depends on many factors, such as the impact of the crash type,  i.e, its severity , the frequency of occurring, and the effort required to implement a fix for the crash type. In this paper, we propose the use of entropy region graphs to triage crash types. An entropy region graph captures the distribution of the occurrences of crash types among the users of a system. We conduct an empirical study on crash reports and bugs, collected from 10 beta releases of Fire fox 4. We show that our proposed triaging technique enables a better classification of crash types than the current triaging used by Fire fox teams. Developers and managers could use such a technique to prioritize crash types during triage, to estimate developer workloads, and to decide which crash types patches should be included in a next release."
"A Sarkar, PC Rigby, B Bartalos",2019,Improving Bug Triaging with High Confidence Predictions at Ericsson,1,"Correctly assigning bugs to the right developer or team, i.e. bug triaging, is a costly activity. A concerted effort at Ericsson has been done to adopt automated bug triaging to reduce development costs. In this work, we replicate the research approaches that have been widely used in the literature. We apply them on over 10k bug reports for 9 large products at Ericsson. We find that a logistic regression classifier including the simple textual and categorical attributes of the bug reports has the highest precision and recall of 78.09  and 79.00 , respectively. Ericsson s bug reports often contain logs that have crash dumps and alarms. We add this information to the bug triage models. We find that this information does not improve the precision and recall of bug triaging in Ericsson s context. Although our models perform as well as the best ones reported in the literature, a criticism of bug triaging at Ericsson is that the accuracy is not sufficient for regular use. We develop a novel approach where we only triage bugs when the model has high confidence in the triage prediction. We find that we improve the accuracy to 90 , but we can make predictions for 62  of the bug reports."
"H Schackmann, H Lichter",2009,Evaluating process quality in GNOME based on change request data,15,"The lifecycle of defects reports and enhancement requests collected in the Bugzilla database of the GNOME project provides valuable information on the evolution of the change request process and for the assessment of process quality in the GNOME sub projects. We present a quality model for the analysis of quality characteristics that is based on evaluating metrics on the Bugzilla database, and illustrate it with a comparative evaluation for 25 of the largest products within GNOME."
"Y Yin, X Dong, T Xu",2018,Rapid and Efficient Bug Assignment Using ELM for IOT Software,0,"The reliable implementation of software in an Internet system directly influences information transmission especially for the Internet of Things  IoT  system. Once defects in the system are found, the communication between things and things and the interaction between people and things in the IoT will be greatly affected. Therefore, rapid and effective defect assignment to the right developer is the key to ensuring software quality and bringing down time consumption in the IoT software life cycle. However, as the size of the software becomes increasing larger, the requirement of users grows, and a large number of software bugs will be found every day. It is difficult for managers to assign the software defects to the appropriate developers. In this paper, a novel hybrid method based on a diversified feature selection and an ensemble extreme learning machine  ELM  is proposed. First, the useful information is extracted from defect reports  then, the data are preprocessed to establish a vector space model  and the diversified feature selection is preprocessed in order to select a smallest set of representative non redundant features with maximal statistical information. Finally, an ensemble GA based ELM training classifier is used. Experimental results show that, compared to SVM, C4.5, NaiveBayes, and KNN classifiers, the proposed ELM based bug triage approach with representative feature selection techniques in this paper significantly improves the efficiency and the effectiveness of bug triages."
"N Imtiaz, L Williams",2019,A synopsis of static analysis alerts on open source software,1,"Static application security testing  SAST  tools detect potential code defects  alerts  without having to execute the code. SASTs are now widely used in practice by both commercial and open source software  OSS . Prior work found that half of the state of the art OSS projects have already employed automated static analysis  1 . However, little public information is available regarding the actionability  important to developers to act upon  of SAST alerts."
"X Xia, D Lo, E Shihab, X Wang, B Zhou",2015,"Automatic, high accuracy prediction of reopened bugs",42,"Bug fixing is one of the most time consuming and costly activities of the software development life cycle. In general, bugs are reported in a bug tracking system, validated by a triage team, assigned for someone to fix, and finally verified and closed. However, in some cases bugs have to be reopened. Reopened bugs increase software maintenance cost, cause rework for already busy developers and in some cases even delay the future delivery of a software release. Therefore, a few recent studies focused on studying reopened bugs. However, these prior studies did not achieve high performance  in terms of precision and recall , required manual intervention, and used very simplistic techniques when dealing with this textual data, which leads us to believe that further improvements are possible. In this paper, we propose ReopenPredictor, which is an automatic, high accuracy predictor of reopened bugs. ReopenPredictor uses a number of features, including textual features, to achieve high accuracy prediction of reopened bugs. As part of ReopenPredictor, we propose two algorithms that are used to automatically estimate various thresholds to maximize the prediction performance. To examine the benefits of ReopenPredictor, we perform experiments on three large open source projects namely Eclipse, Apache HTTP and OpenOffice. Our results show that ReopenPredictor outperforms prior work, achieving a reopened F measure of 0.744, 0.770, and 0.860 for Eclipse, Apache HTTP and OpenOffice, respectively. These results correspond to an improvement in the reopened F measure of the method proposed in the prior work by Shihab et al. by 33.33, 12.57 and 3.12  for Eclipse, Apache HTTP and OpenOffice, respectively."
"TW Thomas, M Tabassum, B Chu ",2018,Security during application development: An application security expert perspective,11,"Many of the security problems that people face today, such as security breaches and data theft, are caused by security vulnerabilities in application source code. Thus, there is a need to understand and improve the experiences of those who can prevent such vulnerabilities in the first place   software developers as well as application security experts. Several studies have examined developers  perceptions and behaviors regarding security vulnerabilities, demonstrating the challenges they face in performing secure programming and utilizing tools for vulnerability detection. We expand upon this work by focusing on those primarily responsible for application security   security auditors. In an interview study of 32 application security experts, we examine their views on application security processes, their workflows, and their interactions with developers in order to further inform the design of tools and processes to improve application security."
"JL Greathouse, T Austin",2011,The potential of sampling for dynamic analysis,3,"This paper presents an argument for distributing dynamic software analyses to large populations of users in order to locate bugs that cause security flaws. We review a collection of dynamic analysis systems and show that, despite a great deal of effort from the research community, their performance is still too low to allow their use in the field. We then show that there are effective sampling mechanisms for accelerating a wide range of powerful dynamic analyses. These mechanisms reduce the rate at which errors are observed by individual analyses, but this loss can be offset by the subsequent increase in test population. Nevertheless, there are unsolved issues in this domain that deserve attention if this technique is to be widely utilized."
"S Park, D Kim, S Son",2019,An Empirical Study of Prioritizing JavaScript Engine Crashes via Machine Learning,0,"The early discovery of security bugs in JavaScript  JS  engines is crucial for protecting Internet users from adversaries abusing zero day vulnerabilities. Browser vendors, bug bounty hunters, and security researchers have been eager to find such security bugs by leveraging state of the art fuzzers as well as their domain expertise. They report a bug when observing a crash after executing their JS test since a crash is an early indicator of a potential bug. However, it is difficult to identify whether such a crash indeed invokes security bugs in JS engines. Thus, unskilled bug reporters are unable to assess the security severity of their new bugs with JS engine crashes. Today, this classification of a reported security bug is completely manual, depending on the verdicts from JS engine vendors. We investigated the feasibility of applying various machine learning classifiers to determine whether an observed crash triggers a security bug. We designed and implemented CRScope, which classifies security and non security bugs from given crash dump files. Our experimental results on 766 crash instances demonstrate that CRScope achieved 0.85, 0.89, and 0.93 Area Under Curve  AUC  for Chakra, V8, and SpiderMonkey crashes, respectively. CRScope also achieved 0.84, 0.89, and 0.95 precision for Chakra, V8, and SpiderMonkey crashes, respectively. This outperforms the previous study and existing tools including Exploitable and AddressSanitizer. CRScope is capable of learning domain specific expertise from the past verdicts on reported bugs and automatically classifying JS engine security bugs, which helps improve the scalable classification of security bugs."
"L Wu, M Grace, Y Zhou, C Wu, X Jiang",2013,The impact of vendor customizations on android security,169,"The smartphone market has grown explosively in recent years, as more and more consumers are attracted to the sensor studded multipurpose devices. Android is particularly ascendant  as an open platform, smartphone manufacturers are free to extend and modify it, allowing them to differentiate themselves from their competitors. However, vendor customizations will inherently impact overall Android security and such impact is still largely unknown. In this paper, we analyze ten representative stock Android images from five popular smartphone vendors  with two models from each vendor . Our goal is to assess the extent of security issues that may be introduced from vendor customizations and further determine how the situation is evolving over time. In particular, we take a three stage process: First, given a smartphone s stock image, we perform provenance analysis to classify each app in the image into three categories: apps originating from the AOSP, apps customized or written by the vendor, and third party apps that are simply bundled into the stock image. Such provenance analysis allows for proper attribution of detected security issues in the examined Android images. Second, we analyze permission usages of pre loaded apps to identify overprivileged ones that unnecessarily request more Android permissions than they actually use. Finally, in vulnerability analysis, we detect buggy pre loaded apps that can be exploited to mount permission re delegation attacks or leak private information. Our evaluation results are worrisome: vendor customizations are significant on stock Android devices and on the whole responsible for the bulk of the security problems we detected in each device. Specifically, our results show that on average 85.78  of all pre loaded apps in examined stock images are overprivileged with a majority of them directly from vendor customizations. In addition, 64.71  to 85.00  of vulnerabilities we detected in examined images from every vendor  except for Sony  arose from vendor customizations. In general, this pattern held over time   newer smartphones, we found, are not necessarily more secure than older ones."
"K Herzig, S Just, A Zeller",2013,"It s not a bug, it s a feature: how misclassification impacts bug prediction",280,"In a manual examination of more than 7,000 issue reports from the bug databases of five open source projects, we found 33.8  of all bug reports to be misclassified   that is, rather than referring to a code fix, they resulted in a new feature, an update to documentation, or an internal refactoring. This misclassification introduces bias in bug prediction models, confusing bugs and features: On average, 39  of files marked as defective actually never had a bug. We discuss the impact of this misclassification on earlier studies and recommend manual data validation for future studies."
"W Xia, Y Li, T Jia, Z Wu",2019,BugIdentifier: An Approach to Identifying Bugs via Log Mining for Accelerating Bug Reporting Stage,0,"Bugs severely damage the reliability of open source software. In order to improve the reliability of open source software, bug tracking system is built to collect and manage bugs reported from users all over the world. When system failures occur, users investigate whether failures are induced by software bugs and then report bugs. However, it is usually difficult and time consuming to identify bugs from system failures. To accelerate bug reporting and reduce the time users spend on identifying bugs, we present BugIdentifier, an automatic bug identifying approach based on log mining. BugIdentifier combines Doc2Vec with Deep Neural Network  DNN  and treats bug identifying as a binary classification problem. Doc2Vec is adopted to train a log sequence embedding model that transforms log sequences into feature vectors, and then DNN is used to identify whether the log sequence is bug induced or not. The results of our empirical evaluation show that our approach can automatically identify real world bugs of Hadoop and OpenStack with the F1 score higher than 75 , specifically, old version bugs of OpenStack can be identified with 97  F1 score, as a result, bug reporting can be accelerated correspondingly."
"R Ruefle, A Dorofee, D Mundie ",2014,Computer security incident response team development and evolution,40,"When computer security incidents occur, it s critical that organizations be able to handle them in a timely manner. The speed with which an organization can recognize, analyze, and respond to an incident will affect the damage and lower recovery costs. Organized incident management requires defined, repeatable processes and the ability to learn from incidents that threaten the confidentiality, availability, and integrity of critical systems and data. Some organizations assign responsibility for incident management to a defined group of people or a designated unit, such as a computer security incident response team. This article looks at the development, purpose, and evolution of such specialized teams  the evolving nature of attacks they must deal with  and methods to evaluate the performance of such teams as well as the emergence of information sharing as a core service."
"JD Strate, PA Laplante",2013,A literature review of research in software defect reporting,31,"In 2002, the National Institute of Standards and Technology  NIST  estimated that software defects cost the U.S. economy in the area of  60 billion a year. It is well known that identifying and tracking these defects efficiently has a measurable impact on software reliability. In this work, we evaluate 104 academic papers on defect reporting published since the NIST report to 2012 to identify the most important advancements in improving software reliability though the efficient identification and tracking of software defects. We categorize the research into the areas of automatic defect detection, automatic defect fixing, attributes of defect reports, quality of defect reports, and triage of defect reports. We then summarize the most important work being done in each area. Finally, we provide conclusions on the current state of the literature, suggest tools and lessons learned from the research for practice, and comment on open research problems."
A Gromova,2017,Defect Report Classification in Accordance with Areas of Testing,3,"There can be thousands of software defects found during testing and submitted into a bug tracking system. This paper intends to reveal the importance of distinguishing different areas of testing in order to be able to perform further meaningful manipulations with defects, compute various metrics, classify or cluster bugs. An area of testing is made up of a group of software components. The Component s field in a bug tracking system usually contains information as to what area the defect belongs to. However, sometimes the field can be empty or does not include all the necessary elements. Moreover, every defect belongs to one or several areas, that is why the classes can overlap within the classification. Therefore it becomes necessary to use the Summary field, which has brief information about the defect. Both fields have text format and require natural language processing. This paper introduces some techniques to classify defect reports according to areas of testing, using the data of two text fields and natural language processing methods and tools."
"B Caglayan, AT Misirli, A Miranskyy, B Turhan ",2012,Factors characterizing reopened issues: a case study,14,"Background: Reopened issues may cause problems in managing software maintenance effort. In order to take actions that will reduce the likelihood of issue reopening the possible causes of bug reopens should be analysed. Aims: In this paper, we investigate potential factors that may cause issue reopening. Method: We have extracted issue activity data from a large release of an enterprise software product. We consider four dimensions, namely developer activity, issue proximity network, static code metrics of the source code changed to fix an issue, issue reports and fixes as possible factors that may cause issue reopening. We have done exploratory analysis on data. We build logistic regression models on data in order to identify key factors leading issue reopening. We have also conducted a survey regarding these factors with the QA Team of the product and interpreted the results. Results: Our results indicate that centrality in the issue proximity network and developer activity are important factors in issue reopening. We have also interpreted our results with the QA Team to point out potential implications for practitioners. Conclusions: Quantitative findings of our study suggest that issue complexity and developers workload play an important role in triggering issue reopening."
"M Borg, P Runeson",2014,"Changes, evolution, and bugs",16,"Changes in evolving software systems are often managed using an issue repository. This repository may contribute to information overload in an organization, but it may also help in navigating the software system. Software developers spend much effort on issue triage, a task in which the mere number of issue reports becomes a significant challenge. One specific difficulty is to determine whether a newly submitted issue report is a duplicate of an issue previously reported, if it contains complementary information related to a known issue, or if the issue report addresses something that has not been observed before. However, the large number of issue reports may also be used to help a developer to navigate the software development project to find related software artifacts, required both to understand the issue itself, and to analyze the impact of a possible issue resolution. This chapter presents recommendation systems that use information in issue repositories to support these two challenges, by supporting either duplicate detection of issue reports or navigation of artifacts in evolving software systems."
"R van Tonder, J Kotheimer, C Le Goues",2018,Semantic crash bucketing,11,"Precise crash triage is important for automated dynamic testing tools, like fuzzers. At scale, fuzzers produce millions of crashing inputs. Fuzzers use heuristics, like stack hashes, to cut down on duplicate bug reports. These heuristics are fast, but often imprecise: even after deduplication, hundreds of uniquely reported crashes can still correspond to the same bug. Remaining crashes must be inspected manually, incurring considerable effort. In this paper we present Semantic Crash Bucketing, a generic method for precise crash bucketing using program transformation. Semantic Crash Bucketing maps crashing inputs to unique bugs as a function of changing a program  i.e., a semantic delta . We observe that a real bug fix precisely identifies crashes belonging to the same bug. Our insight is to approximate real bug fixes with lightweight program transformation to obtain the same level of precision. Our approach uses  a  patch templates and  b  semantic feedback from the program to automatically generate and apply approximate fixes for general bug classes. Our evaluation shows that approximate fixes are competitive with using true fixes for crash bucketing, and significantly outperforms built in deduplication techniques for three state of the art fuzzers."
"Z Huang, M DAngelo, D Miyani ",2016,Talos: Neutralizing vulnerabilities with security workarounds for rapid response,18,"There is often a considerable delay between the discovery of a vulnerability and the issue of a patch. One way to mitigate this window of vulnerability is to use a configuration workaround, which prevents the vulnerable code from being executed at the cost of some lost functionality   but only if one is available. Since application configurations are not specifically designed to mitigate software vulnerabilities, we find that they only cover 25.2  of vulnerabilities. To minimize patch delay vulnerabilities and address the limitations of configuration workarounds, we propose Security Workarounds for Rapid Response  SWRRs , which are designed to neutralize security vulnerabilities in a timely, secure, and unobtrusive manner. Similar to configuration workarounds, SWRRs neutralize vulnerabilities by preventing vulnerable code from being executed at the cost of some lost functionality. However, the key difference is that SWRRs use existing error handling code within applications, which enables them to be mechanically inserted with minimal knowledge of the application and minimal developer effort. This allows SWRRs to achieve high coverage while still being fast and easy to deploy. We have designed and implemented Talos, a system that mechanically instruments SWRRs into a given application, and evaluate it on five popular Linux server applications. We run exploits against 11 real world software vulnerabilities and show that SWRRs neutralize the vulnerabilities in all cases. Quantitative measurements on 320 SWRRs indicate that SWRRs instrumented by Talos can neutralize 75.1  of all potential vulnerabilities and incur a loss of functionality similar to configuration workarounds in 71.3  of those cases. Our overall conclusion is that automatically generated SWRRs can safely mitigate 2.1  more vulnerabilities, while only incurring a loss of functionality comparable to that of traditional configuration workarounds."
AE Hassan,2008,The road ahead for mining software repositories,316,"Source control repositories, bug repositories, archived communications, deployment logs, and code repositories are examples of software repositories that are commonly available for most software projects. The mining software repositories  MSR  field analyzes and cross links the rich data available in these repositories to uncover interesting and actionable information about software systems. By transforming these repositories from static record keeping ones into active repositories, we can guide decision processes in modern software projects. For example, data in source control repositories, traditionally used to archive code, could be linked with data in bug repositories to help practitioners propagate complex changes and to warn them about risky code based on prior changes and bugs. In this paper, we present a brief history of the MSR field and discuss several recent achievements and results of using MSR techniques to support software research and practice. We then discuss the various opportunities and challenges that lie in the road ahead for this important and emerging field."
"B Hawkins, B Demsky, MB Taylor",2016,BlackBox: Lightweight security monitoring for COTS binaries,5,"After a software system is compromised, it can be difficult to understand what vulnerabilities attackers exploited. Any information residing on that machine cannot be trusted as attackers may have tampered with it to cover their tracks. Moreover, even after an exploit is known, it can be difficult to determine whether it has been used to compromise a given machine. Aviation has long used black boxes to better understand the causes of accidents, enabling improvements that reduce the likelihood of future accidents. Many attacks introduce abnormal control flows to compromise systems. In this paper, we present BLACKBOX, a monitoring system for COTS software. Our techniques enable BLACKBOX to efficiently monitor unexpected and potentially harmful control flow in COTS binaries. BlackBox constructs dynamic profiles of an application s typical control flows to filter the vast majority of expected control flow behavior, leaving us with a manageable amount of data that can be logged across the network to remote devices. Modern applications make extensive use of dynamically generated code, some of which varies greatly between executions. We introduce support for code generators that can detect security sensitive behaviors while allowing BLACKBox to avoid logging the majority of ordinary behaviors. We have implemented BlackBox in DynamoRIO. We evaluate the runtime overhead of BlackBox, and show that it can effectively monitor recent versions of Microsoft Office and Google Chrome. We show that in ROP, COOP, and state of the art JIT injection attacks, BlackBox logs the pivotal actions by which the attacker takes control, and can also blacklist those actions to prevent repeated exploits."
"S Razzaq, YF Li, CT Lin, M Xie",2018,A study of the extraction of bug judgment and correction times from open source software bug logs,3,"Cost and time effective solution for software reliability analysis is becoming the biggest concern for open source software development. The open source software development process is a bug driven development and its life cycle cost is mainly incurred in bug correction process. Bug reports, with its various features, play an important role in improving the quality of software products. Unfortunately, less attention is paid towards extraction of important attributes from bug logs. This paper is focused on the comment feature of bug repositories to extract bug judgment and correction times for the open source software reliability model building. A bug report life cycle model is presented and the method to compute the two time points is proposed. The study used datasets from ten official releases of Apache 2.0 to draw empirical results. The proposition is expected to assist in open source software reliability model building."
C Theisen,2015,Automated attack surface approximation,3," While software systems are being developed and released to consumers more rapidly than ever, security remains an important issue for developers. Shorter development cycles means less time for these critical security testing and review efforts. The attack surface of a system is the sum of all paths for untrusted data into and out of a system. Code that lies on the attack surface therefore contains code with actual exploitable vulnerabilities. However, identifying code that lies on the attack surface requires the same contested security resources from the secure testing efforts themselves. My research proposes an automated technique to approximate attack surfaces through the analysis of stack traces. We hypothesize that stack traces user crashes represent activity that puts the system under stress, and is therefore indicative of potential security vulnerabilities. The goal of this research is to aid software engineers in prioritizing security efforts by approximating the attack surface of a system via stack trace analysis. In a trial on Mozilla Firefox, the attack surface approximation selected 8.4  of files and contained 72.1  of known vulnerabilities. A similar trial was performed on the Windows 8 product. "
"M Castro, M Costa, JP Martin",2008,Better bug reporting with better privacy,117,"Software vendors collect bug reports from customers to improve the quality of their software. These reports should include the inputs that make the software fail, to enable vendors to reproduce the bug. However, vendors rarely include these inputs in reports because they may contain private user data. We describe a solution to this problem that provides software vendors with new input values that satisfy the conditions required to make the software follow the same execution path until it fails, but are otherwise unrelated with the original inputs. These new inputs allow vendors to reproduce the bug while revealing less private information than existing approaches. Additionally, we provide a mechanism to measure the amount of information revealed in an error report. This mechanism allows users to perform informed decisions on whether or not to submit reports. We implemented a prototype of our solution and evaluated it with real errors in real programs. The results show that we can produce error reports that allow software vendors to reproduce bugs while revealing almost no private information."
"Z Yin, D Yuan, Y Zhou, S Pasupathy ",2011,How do fixes become bugs?,205,"Software bugs affect system reliability. When a bug is exposed in the field, developers need to fix them. Unfortunately, the bug fixing process can also introduce errors, which leads to buggy patches that further aggravate the damage to end users and erode software vendors  reputation. This paper presents a comprehensive characteristic study on incorrect bug fixes from large operating system code bases including Linux, OpenSolaris, FreeBSD and also a mature commercial OS developed and evolved over the last 12 years, investigating not only themistake patterns during bug fixing but also the possible human reasons in the development process when these incorrect bug fixes were introduced. Our major findings include:  1  at least 14.8 24.4  of sampled fixes for post release bugs in these large OSes are incorrect and have made impacts to end users.  2  Among several common bug types, concurrency bugs are the most difficult to fix correctly: 39  of concurrency bug fixes are incorrect.  3  Developers and reviewers for incorrect fixes usually do not have enough knowledge about the involved code. For example, 27  of the incorrect fixes are made by developers who have never touched the source code files associated with the fix. Our results provide useful guidelines to design new tools and also to improve the development process. Based on our findings, the commercial software vendor whose OS code we evaluated is building a tool to improve the bug fixing and code reviewing process."
"N Pandey, A Hudait, DK Sanyal, A Sen",2018,Automated classification of issue reports from a software issue tracker,5,"Software issue trackers are used by software users and developers to submit bug reports and various other change requests and track them till they are finally closed. However, it is common for submitters to misclassify an improvement request as a bug and vice versa. Hence, it is extremely useful to have an automated classification mechanism for the submitted reports. In this paper we explore how different classifiers might perform this task. We use datasets from the open source projects HttpClient and Lucene. We apply na ve Bayes  NB , support vector machine  SVM , logistic regression  LR  and linear discriminant analysis  LDA  separately for classification and evaluate their relative performance in terms of precision, recall, F measure and accuracy.
"
"A Alipour, A Hindle, E Stroulia",2013,A contextual approach towards more accurate duplicate bug report detection,90,"Bug tracking and issue tracking systems tend to be populated with bugs, issues, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system being discussed. Many bug reporters lack the skills, vocabulary, knowledge, or time to efficiently search the issue tracker for similar issues. As a result, issue trackers are often full of duplicate issues and bugs, and bug triaging is time consuming and error prone. Many researchers have approached the bug deduplication problem using off the shelf information retrieval tools, such as BM25F used by Sun et al. In our work, we extend the state of the art by investigating how contextual information, relying on our prior knowledge of software quality, software architecture, and system development  LDA  topics, can be exploited to improve bug deduplication. We demonstrate the effectiveness of our contextual bug deduplication method on the bug repository of the Android ecosystem. Based on this experience, we conclude that researchers should not ignore the context of software engineering when using IR tools for deduplication."
"LG Huang, V Ng, I Persing, M Chen, Z Li ",2015,AutoODC: Automated generation of orthogonal defect classifications,53,"Orthogonal defect classification  ODC , the most influential framework for software defect classification and analysis, provides valuable in process feedback to system development and maintenance. Conducting ODC classification on existing organizational defect reports is human intensive and requires experts  knowledge of both ODC and system domains. This paper presents AutoODC, an approach for automating ODC classification by casting it as a supervised text classification problem. Rather than merely applying the standard machine learning framework to this task, we seek to acquire a better ODC classification system by integrating experts  ODC experience and domain knowledge into the learning process via proposing a novel relevance annotation framework. We have trained AutoODC using two state of the art machine learning algorithms for text classification, Naive Bayes  NB  and support vector machine  SVM , and evaluated it on both an industrial defect report from the social network domain and a larger defect list extracted from a publicly accessible defect tracker of the open source system FileZilla. AutoODC is a promising approach: not only does it leverage minimal human effort beyond the human annotations typically required by standard machine learning approaches, but it achieves overall accuracies of 82.9    NB  and 80.7    SVM  on the industrial defect report, and accuracies of 77.5    NB  and 75.2    SVM  on the larger, more diversified open source defect list."
ME Zurko,2005,User centered security: Stepping up to the grand challenge,75,"User centered security has been identified as a grand challenge in information security and assurance. It is on the brink of becoming an established subdomain of both security and human computer interface  HCI  research, and an influence on the product development lifecycle. Both security and HCI rely on the reality of interactions with users to prove the utility and validity of their work. As practitioners and researchers in those areas, we still face major issues when applying even the most foundational tools used in either of these fields across both of them. This essay discusses the systemic roadblocks at the social, technical, and pragmatic levels that user centered security must overcome to make substantial breakthroughs. Expert evaluation and user testing are producing effective usable security today. Principles such as safe staging, enumerating usability failure risks, integrated security, transparent security and reliance on trustworthy authorities can also form the basis of improved systems"
"ATT Ying, MP Robillard",2014,Developer profiles for recommendation systems,10,"Developer profiles are representations that capture the characteristics of a software developer, including software development knowledge, organizational information, and communication networks. In recommendation systems in software engineering, developer profiles can be used for personalizing recommendations and for recommending developers who can assist with a task. This chapter describes techniques for capturing, representing, storing, and using developer profiles."
"T Zhang, J Chen, G Yang, B Lee, X Luo",2016,Towards more accurate severity prediction and fixer recommendation of software bugs,48," We propose REPtopic to search the top K nearest neighbours of the new bug report. New algorithms are developed to predict bug severity and recommend bug fixers. Our approach performs better than the previous works on two bug resolution tasks. REPtopic presents better performance than REP and cosine similarity measures. We propose REPtopic to search the top K nearest neighbours of the new bug report. New algorithms are developed to predict bug severity and recommend bug fixers. Our approach performs better than the previous works on two bug resolution tasks. REPtopic presents better performance than REP and cosine similarity measures. Due to the unavoidable bugs appearing in the most of the software systems, bug resolution has become one of the most important activities in software maintenance. For large scale software programs, developers usually depend on bug reports to fix the given bugs. When a new bug is reported, a triager has to complete two important tasks that include severity identification and fixer assignment. The purpose of severity identification is to decide how quickly the bug report should be addressed while fixer assignment means that the new bug needs to be assigned to an appropriate developer for fixing. However, a large number of bug reports submitted every day increase triagers  workload, thus leading to the reduction in the accuracy of severity identification and fixer assignment. Therefore it is necessary to develop an automatic approach to perform severity prediction and fixer recommendation instead of manual work. This article proposes a more accurate approach to accomplish the goal. We firstly utilize modified REP algorithm  i.e., REPtopic  and K Nearest Neighbor  KNN  classification to search the historical bug reports that are similar to a new bug. Next, we extract their features  e.g., assignees and similarity  to develop the severity prediction and fixer recommendation algorithms. Finally, by adopting the proposed algorithms, we achieve severity prediction and semi automatic fixer recommendation on five popular open source projects, including GNU Compiler Collection  GCC , OpenOffice, Eclipse, NetBeans, and Mozilla. The results demonstrated that our method can improve the performance of severity prediction and fixer recommendation through comparison with the cutting edge studies."
"L Neil, A Joshi",2018,Mining Threat Intelligence about Open Source Projects and Libraries from Code Repository Issues and Bug Reports,0,"Open Source Projects and Libraries are being used in software development while also bearing multiple security vulnerabilities. This use of third party ecosystem creates a new kind of attack surface for a product in development. An intelligent attacker can attack a product by exploiting one of the vulnerabilities present in linked projects and libraries.In this paper, we mine threat intelligence about open source projects and libraries from bugs and issues reported on public code repositories. We also track library and project dependencies for installed software on a client machine. We represent and store this threat intelligence, along with the software dependencies in a security knowledge graph. Security analysts and developers can then query and receive alerts from the knowledge graph if any threat intelligence is found about linked libraries and projects, utilized in their products."
"A Aggarwal, G Waghmare, A Sureka",2014,"Mining issue tracking systems using topic models for trend analysis, corpus exploration, and understanding evolution",10," Issue Tracking systems  ITS  such as Google Code Hosting and Bugzilla facilitate software maintenance activities through bug reporting, archiving and fixing. The large number of bug reports and their unstructured text makes it impractical for developers to manually extract actionable intelligence to expedite bug fixing. In this paper, we present an application of mining bug report description and threaded discussion comments using Latent Dirichlet Allocation  LDA  which is a topic modeling technique. We apply LDA on the Chromium Browser Project bug archives  open source  to extract topics  discovery of semantically related terms  and the latent semantic relationship between documents  bug reports  and extracted topics for corpus exploration, trend analysis and understanding evolution in maintenance domain. We conduct a series of experiments to uncover latent topics potentially useful for developers and testers based on the bug meta data such as time, priority, type, category and status. The analysis of reopened and duplicate bugs in particular, has important inferences for the developers and can help in applications such as expertise modeling, resource allocation and knowledge management. "
"C Theisen, K Herzig, P Morrison ",2015,Approximating attack surfaces with stack traces,40,"Security testing and reviewing efforts are a necessity for software projects, but are time consuming and expensive to apply. Identifying vulnerable code supports decision making during all phases of software development. An approach for identifying vulnerable code is to identify its attack surface, the sum of all paths for untrusted data into and out of a system. Identifying the code that lies on the attack surface requires expertise and significant manual effort. This paper proposes an automated technique to empirically approximate attack surfaces through the analysis of stack traces. We hypothesize that stack traces from user initiated crashes have several desirable attributes for measuring attack surfaces. The goal of this research is to aid software engineers in prioritizing security efforts by approximating the attack surface of a system via stack trace analysis. In a trial on Windows 8, the attack surface approximation selected 48.4  of the binaries and contained 94.6  of known vulnerabilities. Compared with vulnerability prediction models  VPMs  run on the entire codebase, VPMs run on the attack surface approximation improved recall from .07 to .1 for binaries and from .02 to .05 for source files. Precision remained at .5 for binaries, while improving from .5 to .69 for source files."
"CL Jones, RA Bridges, KMT Huffer ",2015,Towards a relation extraction framework for cyber security concepts,27,"In order to assist security analysts in obtaining information pertaining to their network, such as novel vulnerabilities, exploits, or patches, information retrieval methods tailored to the security domain are needed. As labeled text data is scarce and expensive, we follow developments in semi supervised Natural Language Processing and implement a bootstrapping algorithm for extracting security entities and their relationships from text. The algorithm requires little input data, specifically, a few relations or patterns  heuristics for identifying relations , and incorporates an active learning component which queries the user on the most important decisions to prevent drifting from the desired relations. Preliminary testing on a small corpus shows promising results, obtaining precision of .82."
"X Li, P Avellino, J Janies ",2016,Software asset analyzer: A system for detecting configuration anomalies,3,"In this paper, we introduce Software Asset Analyzer  SAA , a system that monitors and detects potentially vulnerable software asset modifications in end devices, and can be used to guide patch management. Software patching is a complex and failure prone process that, on enterprise networks, requires triage. Accurate inventories of software  applications and operating systems  improve patching efficiency, which is a significant concern for security analysts. By generating asset baselines, the SAA identifies and reports abnormal deviations in individual end devices, which allows security analysts to identify vulnerable devices and further enforce security patching. This system is also suited for detecting vulnerable software installs and remediation process verification. SAA is a low cost and efficient method that yields accurate and complete inventories of assets on end devices, reducing the potential loss from new vulnerabilities."
"C Zamfir, G Candea",2010,Execution synthesis: a technique for automated software debugging,239,"Debugging real systems is hard, requires deep knowledge of the code, and is time consuming. Bug reports rarely provide sufficient information, thus forcing developers to turn into detectives searching for an explanation of how the program could have arrived at the reported failure point. Execution synthesis is a technique for automating this detective work: given a program and a bug report, it automatically produces an execution of the program that leads to the reported bug symptoms. Using a combination of static analysis and symbolic execution, it  synthesizes  a thread schedule and various required program inputs that cause the bug to manifest. The synthesized execution can be played back deterministically in a regular debugger, like gdb. This is particularly useful in debugging concurrency bugs. Our technique requires no runtime tracing or program modifications, thus incurring no runtime overhead and being practical for use in production systems. We evaluate ESD a debugger based on execution synthesis on popular software  e.g., the SQLite database, ghttpd Web server, HawkNL network library, UNIX utilities : starting from mere bug reports, ESD reproduces on its own several real concurrency and memory safety bugs in less than three minutes."
"AT Chatfield, CG Reddick",2017,Cybersecurity innovation in government: A case study of US pentagon s vulnerability reward program,8,"The U.S. federal governments and agencies face increasingly sophisticated and persistent cyber threats and cyberattacks from black hat hackers who breach cybersecurity for malicious purposes or for personal gain. With the rise of malicious attacks that caused untold financial damage and substantial reputational damage, private sector high tech firms such as Google, Microsoft and Yahoo have adopted an innovative practice known as vulnerability reward program  VRP  or bug bounty program which crowdsources software bug detection from the cybersecurity community. In an alignment with the 2016 U.S. Cybersecurity National Action Plan, the Department of Defense adopted a pilot VRP in 2016. This paper examines the Pentagon s VRP and examines how it may fit with the national cybersecurity policy and the need for new and enhanced cybersecurity capability development. Our case study results show the feasibility of the government adoption and implementation of the innovative concept of VRP to enhance the government cybersecurity posture."
"S Shiaeles, A Chryssanthou, V Katos",2013,On scene triage open source forensic tool chests: Are they effective?,11,"Considering that a triage related task may essentially make or break a digital investigation and the fact that a number of triage tools are freely available online but there is currently no mature framework for practically testing and evaluating them, in this paper we put three open source triage tools to the test. In an attempt to identify common issues, strengths and limitations we evaluate them both in terms of efficiency and compliance to published forensic principles. Our results show that due to the increased complexity and wide variety of system configurations, the triage tools should be made more adaptable, either dynamically or manually  depending on the case and context  instead of maintaining a monolithic functionality."
"S Datta, P Sarkar, S Das, S Sreshtha, P Lade ",2014,How Many Eyeballs Does a Bug Need? An Empirical Validation of Linus  Law,5,"Linus  Law reflects on a key characteristic of open source software development: developers  tendency to closely work together in the bug resolution process. In this paper we empirically examine Linus  Law using a data set of 1,000  Android bugs, owned by 70  developers. Our results indicate that encouraging developers to work closely with one another has nuanced implications  while one form of contact may help reduce bug resolution time, another form can have quite the opposite effect. We present statistically significant evidence in support of our results and discuss their relevance at the individual and organizational levels."
"B Liblit, A Aiken, AX Zheng, MI Jordan",2003,Bug isolation via remote program sampling,688,"We propose a low overhead sampling infrastructure for gathering information from the executions experienced by a program s user community. Several example applications illustrate ways to use sampled instrumentation to isolate bugs. Assertion dense code can be transformed to share the cost of assertions among many users. Lacking assertions, broad guesses can be made about predicates that predict program errors and a process of elimination used to whittle these down to the true bug. Finally, even for non deterministic bugs such as memory corruption, statistical modeling based on logistic regression allows us to identify program behaviors that are strongly correlated with failure and are therefore likely places to look for the error."
"A Kukkar, R Mohana",2018,A Supervised Bug Report Classification with Incorporate and Textual field Knowledge,1,"Performance of the bug prediction model is directly depends on the misclassification of bug reports. Misclassification issue surely scarifies the accuracy of the system. To resolve this issue the manual examination of bug reports are required, but it is very time consuming and tedious job for a developer and tester. In this paper the hybrid approach of merging text mining, natural language processing and machine learning techniques is used to identify bug report as bug or non bug. The four incorporates fields with textual fields are added to bug reports to improve the performance of classifier. TF IDF and Bigram feature extraction methods are used with feature selection and K nearest neighbor  K NN  classifier. The performance of the proposed system is evaluated by using Precision, Recall and F measure by using five datasets. It is observed that the performance of K NN classifier is changed according to the dataset and addition of bigram method improve the performance of classifier."
"L Jonsson, M Borg, D Broman, K Sandahl ",2016,Automated bug assignment: Ensemble based machine learning in large scale industrial contexts,57,"Bug report assignment is an important part of software maintenance. In particular, incorrect assignments of bug reports to development teams can be very expensive in large software development projects. Several studies propose automating bug assignment techniques using machine learning in open source software contexts, but no study exists for large scale proprietary projects in industry. The goal of this study is to evaluate automated bug assignment techniques that are based on machine learning classification. In particular, we study the state of the art ensemble learner Stacked Generalization  SG  that combines several classifiers. We collect more than 50,000 bug reports from five development projects from two companies in different domains. We implement automated bug assignment and evaluate the performance in a set of controlled experiments. We show that SG scales to large scale industrial application and that it outperforms the use of individual classifiers for bug assignment, reaching prediction accuracies from 50   to 89   when large training sets are used. In addition, we show how old training data can decrease the prediction accuracy of bug assignment. We advice industry to use SG for bug assignment in proprietary contexts, using at least 2,000 bug reports for training. Finally, we highlight the importance of not solely relying on results from cross validation when evaluating automated bug assignment."
"N Pandey, DK Sanyal, A Hudait, A Sen",2017,Automated classification of software issue reports using machine learning techniques: an empirical study,20,"Software developers, testers and customers routinely submit issue reports to software issue trackers to record the problems they face in using a software. The issues are then directed to appropriate experts for analysis and fixing. However, submitters often misclassify an improvement request as a bug and vice versa. This costs valuable developer time. Hence automated classification of the submitted reports would be of great practical utility. In this paper, we analyze how machine learning techniques may be used to perform this task. We apply different classification algorithms, namely naive Bayes, linear discriminant analysis, k nearest neighbors, support vector machine  SVM  with various kernels, decision tree and random forest separately to classify the reports from three open source projects. We evaluate their performance in terms of F measure, average accuracy and weighted average F measure. Our experiments show that random forests perform best, while SVM with certain kernels also achieve high performance."
"I Yaqoob, E Ahmed, MH ur Rehman, AIA Ahmed ",2017,The rise of ransomware and emerging security challenges in the Internet of Things,90,"With the increasing miniaturization of smartphones, computers, and sensors in the Internet of Things  IoT  paradigm, strengthening the security and preventing ransomware attacks have become key concerns. Traditional security mechanisms are no longer applicable because of the involvement of resource constrained devices, which require more computation power and resources. This paper presents the ransomware attacks and security concerns in IoT. We initially discuss the rise of ransomware attacks and outline the associated challenges. Then, we investigate, report, and highlight the state of the art research efforts directed at IoT from a security perspective. A taxonomy is devised by classifying and categorizing the literature based on important parameters  e.g., threats, requirements, IEEE standards, deployment level, and technologies . Furthermore, a few credible case studies are outlined to alert people regarding how seriously IoT devices are vulnerable to threats. We enumerate the requirements that need to be met for securing IoT. Several indispensable open research challenges  e.g., data integrity, lightweight security mechanisms, lack of security software s upgradability and patchability features, physical protection of trillions of devices, privacy, and trust  are identified and discussed. Several prominent future research directions are provided."
"X Yang, D Lo, X Xia, L Bao, J Sun",2016,Combining word embedding with information retrieval to recommend similar bug reports,42,"Similar bugs are bugs that require handling of many common code files. Developers can often fix similar bugs with a shorter time and a higher quality since they can focus on fewer code files. Therefore, similar bug recommendation is a meaningful task which can improve development efficiency. Rocha et al. propose the first similar bug recommendation system named NextBug. Although NextBug performs better than a start of the art duplicated bug detection technique REP, its performance is not optimal and thus more work is needed to improve its effectiveness. Technically, it is also rather simple as it relies only upon a standard information retrieval technique, i.e., cosine similarity. In the paper, we propose a novel approach to recommend similar bugs. The approach combines a traditional information retrieval technique and a word embedding technique, and takes bug titles and descriptions as well as bug product and component information into consideration. To evaluate the approach, we use datasets from two popular open source projects, i.e., Eclipse and Mozilla, each of which contains bug reports whose bug ids range from  1,400000 . The results show that our approach improves the performance of NextBug statistically significantly and substantially for both projects."
D Bradbury,2008,Batten down the hatches,1,"Due to the horrifying quantity of vulnerabilities, and often limited time and budget, application and database security can be quite a headache. Limiting privileges and access, however, is a good place to start, finds Danny Bradbury"
"R Duan, A Bijlani, M Xu, T Kim, W Lee",2017,Identifying open source license violation and 1 day security risk at large scale,13,"With millions of apps available to users, the mobile app market is rapidly becoming very crowded. Given the intense competition, the time to market is a critical factor for the success and profitability of an app. In order to shorten the development cycle, developers often focus their efforts on the unique features and workflows of their apps and rely on third party Open Source Software  OSS  for the common features. Unfortunately, despite their benefits, careless use of OSS can introduce significant legal and security risks, which if ignored can not only jeopardize security and privacy of end users, but can also cause app developers high financial loss. However, tracking OSS components, their versions, and interdependencies can be very tedious and error prone, particularly if an OSS is imported with little to no knowledge of its provenance. We therefore propose OSSPolice, a scalable and fully automated tool for mobile app developers to quickly analyze their apps and identify free software license violations as well as usage of known vulnerable versions of OSS. OSSPolice introduces a novel hierarchical indexing scheme to achieve both high scalability and accuracy, and is capable of efficiently comparing similarities of app binaries against a database of hundreds of thousands of OSS sources  billions of lines of code . We populated OSSPolice with 60K C C  and 77K Java OSS sources and analyzed 1.6M free Google Play Store apps. Our results show that 1  over 40K apps potentially violate GPL AGPL licensing terms, and 2  over 100K of apps use known vulnerable versions of OSS. Further analysis shows that developers violate GPL AGPL licensing terms due to lack of alternatives, and use vulnerable versions of OSS despite efforts from companies like Google to improve app security. OSSPolice is available on GitHub."
"F Thung, D Lo, L Jiang, F Rahman ",2015,To what extent could we detect field defects? An extended empirical study of false negatives in static bug finding tools,6,"Software defects can cause much loss. Static bug finding tools are designed to detect and remove software defects and believed to be effective. However, do such tools in fact help prevent actual defects that occur in the field and reported by users? If these tools had been used, would they have detected these field defects, and generated warnings that would direct programmers to fix them? To answer these questions, we perform an empirical study that investigates the effectiveness of five state of the art static bug finding tools  FindBugs, JLint, PMD, CheckStyle, and JCSC  on hundreds of reported and fixed defects extracted from three open source programs  Lucene, Rhino, and AspectJ . Our study addresses the question: To what extent could field defects be detected by state of the art static bug finding tools? Different from past studies that are concerned with the numbers of false positives produced by such tools, we address an orthogonal issue on the numbers of false negatives. We find that although many field defects could be detected by static bug finding tools, a substantial proportion of defects could not be flagged. We also analyze the types of tool warnings that are more effective in finding field defects and characterize the types of missed defects. Furthermore, we analyze the effectiveness of the tools in finding field defects of various severities, difficulties, and types."
"D Hovemeyer, W Pugh",2007,"Finding more null pointer bugs, but not too many",124,"In the summer of 2006, the FindBugs project was challenged to improve the null pointer analysis in FindBugs so that we could find more null pointer bugs. In particular, we were challenged to try to do as well as a publicly available analysis by Reasoning, Inc on version 4.1.24 of Apache Tomcat. Reasoning s report is a result of running their own static analysis tool and using manual auditing to remove false positives. Reasoning reported a total of 9 null pointer warnings in Tomcat 4.1.24, of which only 2 were reported by FindBugs 1.0. While we wanted to improve the analysis in FindBugs, we wanted to retain our current low level of false positives. As of result of the work presented in this paper, FindBugs now reports 4 of the 9 warnings in Tomcat, shows that one of the warnings reported by Reasoning is a false positive, and classifies the remaining 4 as being dependent on the feasibility of a particular path, which cannot be easier ascertained by a local examination of the source code. Moreover, we found 24 additional null pointer bugs in Tomcat that had been missed by Reasoning, and overall doubled the number of null pointer bugs found by FindBugs while improving the quality and significance of reported defects."
"E Bounimova, P Godefroid ",2013,Billions and billions of constraints: Whitebox fuzz testing in production,149,"We report experiences with constraint based whitebox fuzz testing in production across hundreds of large Windows applications and over 500 machine years of computation from 2007 to 2013. Whitebox fuzzing leverages symbolic execution on binary traces and constraint solving to construct new inputs to a program. These inputs execute previously uncovered paths or trigger security vulnerabilities. Whitebox fuzzing has found one third of all file fuzzing bugs during the development of Windows 7, saving millions of dollars in potential security vulnerabilities. The technique is in use today across multiple products at Microsoft. We describe key challenges with running whitebox fuzzing in production. We give principles for addressing these challenges and describe two new systems built from these principles: SAGAN, which collects data from every fuzzing run for further analysis, and JobCenter, which controls deployment of our whitebox fuzzing infrastructure across commodity virtual machines. Since June 2010, SAGAN has logged over 3.4 billion constraints solved, millions of symbolic executions, and tens of millions of test cases generated. Our work represents the largest scale deployment of whitebox fuzzing to date, including the largest usage ever for a Satisfiability Modulo Theories  SMT  solver. We present specific data analyses that improved our production use of whitebox fuzzing. Finally we report data on the performance of constraint solving and dynamic test generation that points toward future research problems."
"C Theisen, K Herzig, B Murphy ",2017,Risk based attack surface approximation: how much data is enough?,12,"Proactive security reviews and test efforts are a necessary component of the software development lifecycle. Resource limitations often preclude reviewing the entire code base. Making informed decisions on what code to review can improve a team s ability to find and remove vulnerabilities. Risk based attack surface approximation  RASA  is a technique that uses crash dump stack traces to predict what code may contain exploitable vulnerabilities. The goal of this research is to help software development teams prioritize security efforts by the efficient development of a risk based attack surface approximation. We explore the use of RASA using Mozilla Firefox and Microsoft Windows stack traces from crash dumps. We create RASA at the file level for Firefox, in which the 15.8  of the files that were part of the approximation contained 73.6  of the vulnerabilities seen for the product. We also explore the effect of random sampling of crashes on the approximation, as it may be impractical for organizations to store and process every crash received. We find that 10 fold random sampling of crashes at a rate of 10  resulted in 3  less vulnerabilities identified than using the entire set of stack traces for Mozilla Firefox. Sampling crashes in Windows 8.1 at a rate of 40  resulted in insignificant differences in vulnerability and file coverage as compared to a rate of 100 ."
"W Zou, D Lo, Z Chen, X Xia, Y Feng ",2018,How practitioners perceive automated bug report management techniques,5,"Bug reports play an important role in the process of debugging and fixing bugs. To reduce the burden of bug report managers and facilitate the process of bug fixing, a great amount of software engineering research has been invested into automated bug report management techniques. However, the verdict is still open whether such techniques are actually required and applicable outside of the theoretical research domain. To fill this gap, in this paper, we conducted a survey among 327 practitioners to gain their insights into various categories of automated bug report management techniques. Specifically, in the survey, we asked them to rate the importance of such techniques and provide the rationales of their ratings. To get deeper insight into practitioners  perspective, we conducted follow up interviews with 25 interviewees selected from the survey respondents. Through the survey and the interviews, we gained a better understanding of the perceived usefulness  or its lack  of different categories of automated bug report management techniques. Based on the survey and interview results, we summarized some potential research directions in developing techniques to help developers better manage bug reports."
"PA Laplante, N Ahmad",2009,Pavlov s bugs: Matching repair policies with rewards,7,"Software maintenance engineers devote a significant amount of work to repairing user identified errors. But user, maintainer, and manager perceptions of an error s importance can vary, and bug repair assignment policies can adversely affect those perceptions."
"B Kasikci, C Zamfir, G Candea",2012,Data races vs. data race bugs: telling the difference with portend,111,"Even though most data races are harmless, the harmful ones are at the heart of some of the worst concurrency bugs. Alas, spotting just the harmful data races in programs is like finding a needle in a haystack: 76 90  of the true data races reported by state of the art race detectors turn out to be harmless  45 . We present Portend, a tool that not only detects races but also automatically classifies them based on their potential consequences: Could they lead to crashes or hangs? Could their effects be visible outside the program? Are they harmless? Our proposed technique achieves high accuracy by efficiently analyzing multiple paths and multiple thread schedules in combination, and by performing symbolic comparison between program outputs. We ran Portend on 7 real world applications: it detected 93 true data races and correctly classified 92 of them, with no human effort. 6 of them are harmful races. Portend s classification accuracy is up to 88  higher than that of existing tools, and it produces easy to understand evidence of the consequences of harmful races, thus both proving their harmfulness and making debugging easier. We envision Portend being used for testing and debugging, as well as for automatically triaging bug reports."
"M Zhang, L Wang, S Jajodia, A Singhal ",2016,Network diversity: a security metric for evaluating the resilience of networks against zero day attacks,69,"Diversity has long been regarded as a security mechanism for improving the resilience of software and networks against various attacks. More recently, diversity has found new applications in cloud computing security, moving target defense, and improving the robustness of network routing. However, most existing efforts rely on intuitive and imprecise notions of diversity, and the few existing models of diversity are mostly designed for a single system running diverse software replicas or variants. At a higher abstraction level, as a global property of the entire network, diversity and its effect on security have received limited attention. In this paper, we take the first step toward formally modeling network diversity as a security metric by designing and evaluating a series of diversity metrics. In particular, we first devise a biodiversity inspired metric based on the effective number of distinct resources. We then propose two complementary diversity metrics, based on the least and the average attacking efforts, respectively. We provide guidelines for instantiating the proposed metrics and present a case study on estimating software diversity. Finally, we evaluate the proposed metrics through simulation."
"D Kong, L Cen, H Jin",2015,Autoreb: Automatically understanding the review to behavior fidelity in android applications,47,"Along with the increasing popularity of mobile devices, there exist severe security and privacy concerns for mobile apps. On Google Play, user reviews provide a unique understanding of security privacy issues of mobile apps from users  perspective, and in fact they are valuable feedbacks from users by considering users  expectations. To best assist the end users, in this paper, we automatically learn the security privacy related behaviors inferred from analysis on user reviews, which we call review to behavior fidelity. We design the system AUTOREB that automatically assesses the review to behavior fidelity of mobile apps. AUTOREB employs the state of the art machine learning techniques to infer the relations between users  reviews and four categories of security related behaviors. Moreover, it uses a crowdsourcing approach to automatically aggregate the security issues from review level to app level. To our knowledge, AUTOREB is the first work that explores the user review information and utilizes the review semantics to predict the risky behaviors at both review level and app level. We crawled a real world dataset of 2,614,186 users, 12,783 apps and 13,129,783 reviews from Google play, and use it to comprehensively evaluate AUTOREB. The experiment result shows that our method can predict the mobile app behaviors at user review level with accuracy as high as 94.05 , and also it can predict the security issues at app level by aggregating the predictions at review level. Our research offers an insight into understanding the mobile app security concerns from users  perspective, and helps bridge the gap between the security issues and users  perception."
"L Jonsson, D Broman, M Magnusson ",2016,Automatic localization of bugs to faulty components in large scale software systems using bayesian classification,6,"We suggest a Bayesian approach to the problem of reducing bug turn around time in large software development organizations. Our approach is to use classification to predict where bugs are located in components. This classification is a form of automatic fault localization  AFL  at the component level. The approach only relies on historical bug reports and does not require detailed analysis of source code or detailed test runs. Our approach addresses two problems identified in user studies of AFL tools. The first problem concerns the trust in which the user can put in the results of the tool. The second problem concerns understanding how the results were computed. The proposed model quantifies the uncertainty in its predictions and all estimated model parameters. Additionally, the output of the model explains why a result was suggested. We evaluate the approach on more than 50000 bugs."
"A Rastogi, A Gupta, A Sureka",2013,Samiksha: mining issue tracking system for contribution and performance assessment,11,"Individual contribution and performance assessment is a standard practice conducted in organizations to measure the value addition by various contributors. Accurate measurement of individual contributions based on pre defined objectives, roles and Key Performance Indicators  KPIs  is a challenging task. In this paper, we propose a contribution and performance assessment framework  called as Samiksha  in the context of Software Maintenance. The focus of the study presented in this paper is Software Maintenance Activities  such as bug fixing and feature enhancement  performed by bug reporters, bug triagers, bug fixers, software developers, quality assurance and project managers facilitated by an Issue Tracking System. We present the result of a survey that we conducted to understand practitioner s perspective and experience  specifically on the topic of contribution assessment for software maintenance professionals . We propose several performance metrics covering different aspects  such as number of bugs fixed weighted by priority and quality of bugs reported  and various roles  such as bug reporter and bug fixer . We conduct a series of experiments on Google Chromium Project data  extracting data from the issue tracker for Google Chromium Project  and present results demonstrating the effectiveness of our proposed framework."
"Y Dang, D Zhang, S Ge, R Huang ",2017,Transferring code clone detection and analysis to practice,12,"During software development, code clones are commonly produced, in the form of a number of the same or similar code fragments spreading within one or many large code bases. Numerous research projects have been carried out on empirical studies or tool support for detecting or analyzing code clones. However, in practice, few such research projects have resulted in substantial industry adoption. In this paper, we report our experiences of transferring XIAO, a code clone detection and analysis approach and its supporting tool, to road industrial practices:  1  shipped in Visual Studio 2012, a widely used industrial IDE,  2  deployed and intensively used at the Microsoft Security Response Center. According to our experiences, technology transfer is a rather complicated journey that needs significant efforts from both the technical aspect and social aspect. From the technical aspect, significant efforts are needed to adapt a research prototype to a product quality tool that addresses the needs of real scenarios, to be integrated into a mainstream product or development process. From the social aspect, there are strong needs to interact with practitioners to identify killer scenarios in industrial settings, figure out the gap between a research prototype and a tool fitting the needs of real scenarios, to understand the requirements of releasing with a mainstream product, being integrated into a development process, understanding their release cadence, etc."
"O Baysal, R Holmes, MW Godfrey",2014,No issue left behind: Reducing information overload in issue tracking,18," Modern software development tools such as issue trackers are often complex and multi purpose tools that provide access to an immense amount of raw information. Unfortunately, developers sometimes feel frustrated when they cannot easily obtain the particular information they need for a given task  furthermore, the constant influx of new data   the vast majority of which is irrelevant to their task at hand   may result in issues being  dropped on the floor . In this paper, we present a developer centric approach to issue tracking that aims to reduce information overload and improve developers  situational awareness. Our approach is motivated by a grounded theory study of developer comments, which suggests that customized views of a project s repositories that are tailored to developer specific tasks can help developers better track their progress and understand the surrounding technical context. From the qualitative study, we uncovered a model of the kinds of information elements that are essential for developers in completing their daily tasks, and from this model we built a tool organized around customized issue tracking dashboards. Further quantitative and qualitative evaluation demonstrated that this dashboard like approach to issue tracking can reduce the volume of irrelevant emails by over 99  and also improve support for specific issue tracking tasks. "
